{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "bBNeKAyF3Y-h"
   },
   "source": [
    "# 4a. Data Augmentation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Google Colab Setup\n",
    "First off, we need to run a few commands to set up our environment on Google Colab. If you are running this notebook on a local machine you can skip this section, but you will need to use the environment.yaml file to set up your Python environment and use it for your Jupyter kernel.\n",
    "\n",
    "Run the following cell to mount your Google Drive. Follow the link, sign in to your Google account (the same account you used to store this notebook!)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from google.colab import drive\n",
    "drive.mount('/content/drive')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now remember the path in your Google Drive where you uploaded this notebook, fill it in below. If all functions properly, executing the next cell should display the filenames from the assignment:\n",
    "\n",
    "```\n",
    "['03_asl_cnn.ipynb', 'data', 'images', '02_asl.ipynb', '01_mnist.ipynb']\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "\n",
    "# TODO: Fill in the Google Drive path where you uploaded assignment1\n",
    "# Example: If you create a Fall2023 folder and put all the files under A1 folder, then 'Fall2023/A1'\n",
    "GOOGLE_DRIVE_PATH_POST_MYDRIVE = 'CS5388_PyTorch1'\n",
    "GOOGLE_DRIVE_PATH = os.path.join('/content', 'drive', 'MyDrive', GOOGLE_DRIVE_PATH_POST_MYDRIVE)\n",
    "print(os.listdir(GOOGLE_DRIVE_PATH))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "\n",
    "sys.path.append(GOOGLE_DRIVE_PATH)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Local Setup OR Google Drive\n",
    "Run the cell below regardless of whether you are using google drive or local setup."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Running locally.\n"
     ]
    }
   ],
   "source": [
    "# if running locally set GOOGLE PATH\n",
    "import sys\n",
    "if 'google.colab' in sys.modules:\n",
    "  print(f'Running in google colab. Our path is `{GOOGLE_DRIVE_PATH}`')\n",
    "else:\n",
    "  GOOGLE_DRIVE_PATH = '.'\n",
    "  print('Running locally.')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "HTHY1Otu3Y-h"
   },
   "source": [
    "So far, we've selected a model architecture that vastly improves the model's performance, as it is designed to recognize important features in the images. The validation accuracy is still lagging behind the training accuracy, which is a sign of overfitting: the model is getting confused by things it has not seen before when it tests against the validation dataset.\n",
    "\n",
    "In order to teach our model to be more robust when looking at new data, we're going to programmatically increase the size and variance in our dataset. This is known as [*data augmentation*](https://link.springer.com/article/10.1186/s40537-019-0197-0), a useful technique for many deep learning applications.\n",
    "\n",
    "The increase in size gives the model more images to learn from while training. The increase in variance helps the model ignore unimportant features and select only the features that are truly important in classification, allowing it to generalize better."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "k01AskqI3Y-h"
   },
   "source": [
    "## 4a.1 Objectives"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "YCFOyxKS3Y-h"
   },
   "source": [
    "* Augment the ASL dataset\n",
    "* Use the augmented data to train an improved model\n",
    "* Save the well-trained model to disk for use in deployment"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 6560,
     "status": "ok",
     "timestamp": 1715241340700,
     "user": {
      "displayName": "Danielle Detering US",
      "userId": "15432464718872067879"
     },
     "user_tz": 420
    },
    "id": "ocl26UO63Y-i",
    "outputId": "b097ecfc-e330-4c6e-d386-4b2b7cbb55bb"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "False"
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import torch.nn as nn\n",
    "import pandas as pd\n",
    "import torch\n",
    "from torch.optim import Adam\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "import torchvision.transforms.v2 as transforms\n",
    "import torchvision.transforms.functional as F\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "import utils\n",
    "\n",
    "import torch._dynamo\n",
    "torch._dynamo.config.suppress_errors = True\n",
    "\n",
    "\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "torch.cuda.is_available()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "u-FCWlRg3Y-h"
   },
   "source": [
    "## 4a.2 Preparing the Data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "JjSagpmG3Y-i"
   },
   "source": [
    "As we're in a new notebook, we will load and process our data again. To do this, execute the following cell:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {
    "executionInfo": {
     "elapsed": 3988,
     "status": "ok",
     "timestamp": 1715241345056,
     "user": {
      "displayName": "Danielle Detering US",
      "userId": "15432464718872067879"
     },
     "user_tz": 420
    },
    "id": "jYhhD7yo2WEI"
   },
   "outputs": [],
   "source": [
    "IMG_HEIGHT = 28\n",
    "IMG_WIDTH = 28\n",
    "IMG_CHS = 1\n",
    "N_CLASSES = 24\n",
    "\n",
    "train_df = pd.read_csv(f\"{GOOGLE_DRIVE_PATH}/data/asl_data/sign_mnist_train.csv\")\n",
    "valid_df = pd.read_csv(f\"{GOOGLE_DRIVE_PATH}/data/asl_data/sign_mnist_valid.csv\")\n",
    "\n",
    "class MyDataset(Dataset):\n",
    "    def __init__(self, base_df):\n",
    "        x_df = base_df.copy()\n",
    "        y_df = x_df.pop('label')\n",
    "        x_df = x_df.values / 255  # Normalize values from 0 to 1\n",
    "        x_df = x_df.reshape(-1, IMG_CHS, IMG_WIDTH, IMG_HEIGHT)\n",
    "        self.xs = torch.tensor(x_df).float().to(device)\n",
    "        self.ys = torch.tensor(y_df).to(device)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        x = self.xs[idx]\n",
    "        y = self.ys[idx]\n",
    "        return x, y\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.xs)\n",
    "\n",
    "n = 32\n",
    "train_data = MyDataset(train_df)\n",
    "train_loader = DataLoader(train_data, batch_size=n, shuffle=True)\n",
    "train_N = len(train_loader.dataset)\n",
    "\n",
    "valid_data = MyDataset(valid_df)\n",
    "valid_loader = DataLoader(valid_data, batch_size=n)\n",
    "valid_N = len(valid_loader.dataset)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "qwsfoZkE3Y-i"
   },
   "source": [
    "## 4a.3 Model Creation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "ze7Tv-Aj3Y-i"
   },
   "source": [
    "We will also need to create our model again. As we learned in the last lesson, convolutional neural networks use a repeated sequence of layers. Let's take advantage of this pattern to make our own [custom module](https://pytorch.org/tutorials/beginner/examples_nn/two_layer_net_module.html). We can then use this module like a layer in our [Sequential](https://pytorch.org/docs/stable/generated/torch.nn.Sequential.html) model.\n",
    "\n",
    "To do this, we will extend the [Module](https://pytorch.org/docs/stable/generated/torch.nn.Module.html) class. Then we will define two methods:\n",
    "* `__init__`: defines any properties we want our module to have, including our neural network layers. We will effectively be using a model within a model.\n",
    "* `forward`: defines how we want the module to process any incoming data from the previous layer it is connected to. Since we are using a `Sequential` model, we can pass the input data into it like we are making a prediction."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {
    "executionInfo": {
     "elapsed": 322,
     "status": "ok",
     "timestamp": 1715241347583,
     "user": {
      "displayName": "Danielle Detering US",
      "userId": "15432464718872067879"
     },
     "user_tz": 420
    },
    "id": "_o8Y7C91Bfl8"
   },
   "outputs": [],
   "source": [
    "class MyConvBlock(nn.Module):\n",
    "    def __init__(self, in_ch, out_ch, dropout_p):\n",
    "        kernel_size = 3\n",
    "        super().__init__()\n",
    "\n",
    "        self.model = nn.Sequential(\n",
    "            nn.Conv2d(in_ch, out_ch, kernel_size, stride=1, padding=1),\n",
    "            nn.BatchNorm2d(out_ch),\n",
    "            nn.ReLU(),\n",
    "            nn.Dropout(dropout_p),\n",
    "            nn.MaxPool2d(2, stride=2)\n",
    "        )\n",
    "\n",
    "    def forward(self, x):\n",
    "        return self.model(x)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now that we've define our custom module, let's see it in action. The below model ia archecturially the same as in the previous lesson. Can you see the connection?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {
    "executionInfo": {
     "elapsed": 2,
     "status": "ok",
     "timestamp": 1715241351435,
     "user": {
      "displayName": "Danielle Detering US",
      "userId": "15432464718872067879"
     },
     "user_tz": 420
    },
    "id": "I0A_7iJvB8Kc"
   },
   "outputs": [],
   "source": [
    "flattened_img_size = 75 * 3 * 3\n",
    "\n",
    "# Input 1 x 28 x 28\n",
    "base_model = nn.Sequential(\n",
    "    MyConvBlock(IMG_CHS, 25, 0), # 25 x 14 x 14\n",
    "    MyConvBlock(25, 50, 0.2), # 50 x 7 x 7\n",
    "    MyConvBlock(50, 75, 0),  # 75 x 3 x 3\n",
    "    # Flatten to Dense Layers\n",
    "    nn.Flatten(),\n",
    "    nn.Linear(flattened_img_size, 512),\n",
    "    nn.Dropout(.3),\n",
    "    nn.ReLU(),\n",
    "    nn.Linear(512, N_CLASSES)\n",
    ")\n",
    "\n",
    "model = base_model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "When we print the model, not only will it now show the use of our custom module, it will also show the layers within our custom module:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 465,
     "status": "ok",
     "timestamp": 1715241354080,
     "user": {
      "displayName": "Danielle Detering US",
      "userId": "15432464718872067879"
     },
     "user_tz": 420
    },
    "id": "4THc2t0HhNcv",
    "outputId": "e25d69a9-e51a-4a90-90df-dc69a586f54b"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "OptimizedModule(\n",
       "  (_orig_mod): Sequential(\n",
       "    (0): MyConvBlock(\n",
       "      (model): Sequential(\n",
       "        (0): Conv2d(1, 25, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "        (1): BatchNorm2d(25, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (2): ReLU()\n",
       "        (3): Dropout(p=0, inplace=False)\n",
       "        (4): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
       "      )\n",
       "    )\n",
       "    (1): MyConvBlock(\n",
       "      (model): Sequential(\n",
       "        (0): Conv2d(25, 50, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "        (1): BatchNorm2d(50, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (2): ReLU()\n",
       "        (3): Dropout(p=0.2, inplace=False)\n",
       "        (4): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
       "      )\n",
       "    )\n",
       "    (2): MyConvBlock(\n",
       "      (model): Sequential(\n",
       "        (0): Conv2d(50, 75, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "        (1): BatchNorm2d(75, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (2): ReLU()\n",
       "        (3): Dropout(p=0, inplace=False)\n",
       "        (4): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
       "      )\n",
       "    )\n",
       "    (3): Flatten(start_dim=1, end_dim=-1)\n",
       "    (4): Linear(in_features=675, out_features=512, bias=True)\n",
       "    (5): Dropout(p=0.3, inplace=False)\n",
       "    (6): ReLU()\n",
       "    (7): Linear(in_features=512, out_features=24, bias=True)\n",
       "  )\n",
       ")"
      ]
     },
     "execution_count": 48,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "loss_function = nn.CrossEntropyLoss()\n",
    "optimizer = Adam(base_model.parameters())\n",
    "\n",
    "model = torch.compile(base_model.to(device))\n",
    "model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Custom modules are flexible, and we can define any other methods or properties we wish to have. This makes them powerful when data scientists are trying to solve complex problems."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "kjBNCzfc3Y-j"
   },
   "source": [
    "## 4a.4 Data Augmentation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "y8HdHKtM3Y-j"
   },
   "source": [
    "Before defining our training loop, it's time to set up our data augmentation.\n",
    "\n",
    "We've seen [TorchVision](https://pytorch.org/vision/stable/index.html)'s [Transforms](https://pytorch.org/vision/0.9/transforms.html) before, but in this lesson, we will further explore its data augmentation tools. First, let's get a sample image to test with:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 312,
     "status": "ok",
     "timestamp": 1715241358482,
     "user": {
      "displayName": "Danielle Detering US",
      "userId": "15432464718872067879"
     },
     "user_tz": 420
    },
    "id": "-LT7NvrXhYwB",
    "outputId": "4c1c1af4-811b-46d7-fa73-594772907549"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([1, 28, 28])"
      ]
     },
     "execution_count": 49,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "row_0 = train_df.head(1)\n",
    "y_0 = row_0.pop('label')\n",
    "x_0 = row_0.values / 255\n",
    "x_0 = x_0.reshape(IMG_CHS, IMG_WIDTH, IMG_HEIGHT)\n",
    "x_0 = torch.tensor(x_0)\n",
    "x_0.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 447
    },
    "executionInfo": {
     "elapsed": 332,
     "status": "ok",
     "timestamp": 1715241364072,
     "user": {
      "displayName": "Danielle Detering US",
      "userId": "15432464718872067879"
     },
     "user_tz": 420
    },
    "id": "XKFRYIpvkUEF",
    "outputId": "fb3f72ab-ce59-4bfc-a54a-0a4d575e497c"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.image.AxesImage at 0x399696350>"
      ]
     },
     "execution_count": 50,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "image = F.to_pil_image(x_0)\n",
    "plt.imshow(image, cmap='gray')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4a.4.1 [RandomResizeCrop](https://pytorch.org/vision/0.9/transforms.html#torchvision.transforms.RandomResizedCrop)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This transform will randomly resize the input image based on `scale`, and then [crop](https://en.wikipedia.org/wiki/Cropping_(image)) it to a size we specify. In this case, we will crop it to the original image dimensions. To do this, TorchVision needs to know the [aspect ratio](https://en.wikipedia.org/wiki/Aspect_ratio_(image)) of the image it is scaling. Since our height is the same as our width, our aspect `ratio` is 1:1."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {
    "executionInfo": {
     "elapsed": 2,
     "status": "ok",
     "timestamp": 1715241375000,
     "user": {
      "displayName": "Danielle Detering US",
      "userId": "15432464718872067879"
     },
     "user_tz": 420
    },
    "id": "qWINTqKypE5J"
   },
   "outputs": [],
   "source": [
    "trans = transforms.Compose([\n",
    "    transforms.RandomResizedCrop((IMG_WIDTH, IMG_HEIGHT), scale=(.7, 1), ratio=(1, 1)),\n",
    "])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Try running the below cell a few times. It should be different each time."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 447
    },
    "executionInfo": {
     "elapsed": 507,
     "status": "ok",
     "timestamp": 1715241377237,
     "user": {
      "displayName": "Danielle Detering US",
      "userId": "15432464718872067879"
     },
     "user_tz": 420
    },
    "id": "6ZugUNuJpPG2",
    "outputId": "52caec17-6a25-4484-c2f4-2aed78b5ffe8"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.image.AxesImage at 0x3f9de8050>"
      ]
     },
     "execution_count": 52,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "new_x_0 = trans(x_0)\n",
    "image = F.to_pil_image(new_x_0)\n",
    "plt.imshow(image, cmap='gray')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 333,
     "status": "ok",
     "timestamp": 1715241385987,
     "user": {
      "displayName": "Danielle Detering US",
      "userId": "15432464718872067879"
     },
     "user_tz": 420
    },
    "id": "8VQJ1vwKp4nJ",
    "outputId": "63521e3a-5a63-48c8-8823-bd60d6814b64"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([1, 28, 28])"
      ]
     },
     "execution_count": 53,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "new_x_0.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4a.4.2 [RandomHorizontalFlip](https://pytorch.org/vision/0.9/transforms.html#torchvision.transforms.RandomHorizontalFlip)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Yrmm_inJ3Y-j"
   },
   "source": [
    "We can also randomly flip our images [Horizontally](https://pytorch.org/vision/0.9/transforms.html#torchvision.transforms.RandomHorizontalFlip) or [Vertically](https://pytorch.org/vision/0.9/transforms.html#torchvision.transforms.RandomVerticalFlip). However, for these images, we will only flip them horizontally.\n",
    "\n",
    "Take a moment to think about why we would want to flip images horizontally, but not vertically. When you have an idea, reveal the text below."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "XCLufCeF3Y-j"
   },
   "source": [
    "`# SOLUTION` Fun fact: American Sign Language can be done with either the left or right hand being dominant. However, it is unlikely to see sign language from upside down. This kind of domain-specific reasoning can help make good decisions for your own deep learning applications."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [],
   "source": [
    "trans = transforms.Compose([\n",
    "    transforms.RandomHorizontalFlip()\n",
    "])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Try running the below cell a few times. Does the image flip about half the time?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.image.AxesImage at 0x3f9d6de50>"
      ]
     },
     "execution_count": 55,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "new_x_0 = trans(x_0)\n",
    "image = F.to_pil_image(new_x_0)\n",
    "plt.imshow(image, cmap='gray')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4a.4.3 [RandomRotation](https://pytorch.org/vision/0.9/transforms.html#torchvision.transforms.RandomRotation)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can also randomly rotate the image to add more variability. Just like with with other augmentation techniques, it's easy to accidentally go too far. With ASL, if we rotate too much, our `D`s might look like `G`s and visa versa. Because of this, let's limit it to `30` degrees."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [],
   "source": [
    "trans = transforms.Compose([\n",
    "    transforms.RandomRotation(30)\n",
    "])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "When we run the cell block below, some black pixels may appear. The corners or our image disappear when we rotate, and for almost every pixel we lose, we gain an empty pixel."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.image.AxesImage at 0x3f9da3c50>"
      ]
     },
     "execution_count": 57,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "new_x_0 = trans(x_0)\n",
    "image = F.to_pil_image(new_x_0)\n",
    "plt.imshow(image, cmap='gray')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4a.4.3 [ColorJitter](https://pytorch.org/vision/0.9/transforms.html#torchvision.transforms.ColorJitter)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The `ColorJitter` transform has 4 arguments:\n",
    "* [brightness](https://en.wikipedia.org/wiki/Brightness)\n",
    "* [contrast](https://en.wikipedia.org/wiki/Contrast_(vision))\n",
    "* [saturation](https://en.wikipedia.org/wiki/Colorfulness#Saturation)\n",
    "* [hue](https://en.wikipedia.org/wiki/Hue)\n",
    "\n",
    "\n",
    "The latter 2 apply to color images, so we will only use the first 2 for now."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [],
   "source": [
    "brightness = .2  # Change to be from 0 to 1\n",
    "contrast = .5  # Change to be from 0 to 1\n",
    "\n",
    "trans = transforms.Compose([\n",
    "    transforms.ColorJitter(brightness=brightness, contrast=contrast)\n",
    "])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Try running the below a few times, but also try changing either `brightness` or `contrast` to `1`. Get any intersting results?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.image.AxesImage at 0x3f9c29a90>"
      ]
     },
     "execution_count": 59,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "new_x_0 = trans(x_0)\n",
    "image = F.to_pil_image(new_x_0)\n",
    "plt.imshow(image, cmap='gray')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4a.3.4 [Compose](https://pytorch.org/vision/0.9/transforms.html#torchvision.transforms.Compose)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Time to bring it all together. We can create a sequence of these random transformations with `Compose`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {
    "executionInfo": {
     "elapsed": 1,
     "status": "ok",
     "timestamp": 1715241387886,
     "user": {
      "displayName": "Danielle Detering US",
      "userId": "15432464718872067879"
     },
     "user_tz": 420
    },
    "id": "ZkXjesFKFH_b"
   },
   "outputs": [],
   "source": [
    "random_transforms = transforms.Compose([\n",
    "    transforms.RandomRotation(5),\n",
    "    transforms.RandomResizedCrop((IMG_WIDTH, IMG_HEIGHT), scale=(.9, 1), ratio=(1, 1)),\n",
    "    transforms.RandomHorizontalFlip(),\n",
    "    transforms.ColorJitter(brightness=.2, contrast=.5)\n",
    "])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's test it out. With all the different combinations how many varations are there of this one image? Infinite?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 447
    },
    "executionInfo": {
     "elapsed": 347,
     "status": "ok",
     "timestamp": 1715241391170,
     "user": {
      "displayName": "Danielle Detering US",
      "userId": "15432464718872067879"
     },
     "user_tz": 420
    },
    "id": "ewG_7NAgqEnf",
    "outputId": "24142f9f-286f-42ab-9769-bfd38c9defbf"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.image.AxesImage at 0x3f9c23890>"
      ]
     },
     "execution_count": 61,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "new_x_0 = random_transforms(x_0)\n",
    "image = F.to_pil_image(new_x_0)\n",
    "plt.imshow(image, cmap='gray')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4a.4 Training with Augmentation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Our training is mostly the same, but there is one line of change. Before passing our images to our model, we will apply our `random_transforms`. For conveneince, we moved `get_batch_accuracy` to a [utils](./utils.py) file."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {
    "executionInfo": {
     "elapsed": 317,
     "status": "ok",
     "timestamp": 1715241479297,
     "user": {
      "displayName": "Danielle Detering US",
      "userId": "15432464718872067879"
     },
     "user_tz": 420
    },
    "id": "IcgAmvx7rI13"
   },
   "outputs": [],
   "source": [
    "def train():\n",
    "    loss = 0\n",
    "    accuracy = 0\n",
    "\n",
    "    model.train()\n",
    "    for x, y in train_loader:\n",
    "        output = model(random_transforms(x))  # Updated\n",
    "        optimizer.zero_grad()\n",
    "        batch_loss = loss_function(output, y)\n",
    "        batch_loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "        loss += batch_loss.item()\n",
    "        accuracy += utils.get_batch_accuracy(output, y, train_N)\n",
    "    print('Train - Loss: {:.4f} Accuracy: {:.4f}'.format(loss, accuracy))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "On the other hamd, validation remains the same. There are no random transformations. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {
    "executionInfo": {
     "elapsed": 382,
     "status": "ok",
     "timestamp": 1715241482250,
     "user": {
      "displayName": "Danielle Detering US",
      "userId": "15432464718872067879"
     },
     "user_tz": 420
    },
    "id": "iXc6lnRAR4qZ"
   },
   "outputs": [],
   "source": [
    "def validate():\n",
    "    loss = 0\n",
    "    accuracy = 0\n",
    "\n",
    "    model.eval()\n",
    "    with torch.no_grad():\n",
    "        for x, y in valid_loader:\n",
    "            output = model(x)\n",
    "\n",
    "            loss += loss_function(output, y).item()\n",
    "            accuracy += utils.get_batch_accuracy(output, y, valid_N)\n",
    "    print('Valid - Loss: {:.4f} Accuracy: {:.4f}'.format(loss, accuracy))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's put data augmentation to the test. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 45384,
     "status": "ok",
     "timestamp": 1715241529445,
     "user": {
      "displayName": "Danielle Detering US",
      "userId": "15432464718872067879"
     },
     "user_tz": 420
    },
    "id": "isjOJIVArTLR",
    "outputId": "5d4b6a5f-2ad9-4276-d65e-d84b9874ec3b"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "W0404 11:45:02.289000 54198 site-packages/torch/_dynamo/convert_frame.py:1233] WON'T CONVERT inner /opt/anaconda3/envs/cs5388-a1/lib/python3.13/site-packages/torch/_dynamo/external_utils.py line 43 \n",
      "W0404 11:45:02.289000 54198 site-packages/torch/_dynamo/convert_frame.py:1233] due to: \n",
      "W0404 11:45:02.289000 54198 site-packages/torch/_dynamo/convert_frame.py:1233] Traceback (most recent call last):\n",
      "W0404 11:45:02.289000 54198 site-packages/torch/_dynamo/convert_frame.py:1233]   File \"/opt/anaconda3/envs/cs5388-a1/lib/python3.13/site-packages/torch/_dynamo/convert_frame.py\", line 1164, in __call__\n",
      "W0404 11:45:02.289000 54198 site-packages/torch/_dynamo/convert_frame.py:1233]     result = self._inner_convert(\n",
      "W0404 11:45:02.289000 54198 site-packages/torch/_dynamo/convert_frame.py:1233]         frame, cache_entry, hooks, frame_state, skip=skip + 1\n",
      "W0404 11:45:02.289000 54198 site-packages/torch/_dynamo/convert_frame.py:1233]     )\n",
      "W0404 11:45:02.289000 54198 site-packages/torch/_dynamo/convert_frame.py:1233]   File \"/opt/anaconda3/envs/cs5388-a1/lib/python3.13/site-packages/torch/_dynamo/convert_frame.py\", line 547, in __call__\n",
      "W0404 11:45:02.289000 54198 site-packages/torch/_dynamo/convert_frame.py:1233]     return _compile(\n",
      "W0404 11:45:02.289000 54198 site-packages/torch/_dynamo/convert_frame.py:1233]         frame.f_code,\n",
      "W0404 11:45:02.289000 54198 site-packages/torch/_dynamo/convert_frame.py:1233]     ...<14 lines>...\n",
      "W0404 11:45:02.289000 54198 site-packages/torch/_dynamo/convert_frame.py:1233]         skip=skip + 1,\n",
      "W0404 11:45:02.289000 54198 site-packages/torch/_dynamo/convert_frame.py:1233]     )\n",
      "W0404 11:45:02.289000 54198 site-packages/torch/_dynamo/convert_frame.py:1233]   File \"/opt/anaconda3/envs/cs5388-a1/lib/python3.13/site-packages/torch/_dynamo/convert_frame.py\", line 986, in _compile\n",
      "W0404 11:45:02.289000 54198 site-packages/torch/_dynamo/convert_frame.py:1233]     guarded_code = compile_inner(code, one_graph, hooks, transform)\n",
      "W0404 11:45:02.289000 54198 site-packages/torch/_dynamo/convert_frame.py:1233]   File \"/opt/anaconda3/envs/cs5388-a1/lib/python3.13/site-packages/torch/_dynamo/convert_frame.py\", line 715, in compile_inner\n",
      "W0404 11:45:02.289000 54198 site-packages/torch/_dynamo/convert_frame.py:1233]     return _compile_inner(code, one_graph, hooks, transform)\n",
      "W0404 11:45:02.289000 54198 site-packages/torch/_dynamo/convert_frame.py:1233]   File \"/opt/anaconda3/envs/cs5388-a1/lib/python3.13/site-packages/torch/_utils_internal.py\", line 95, in wrapper_function\n",
      "W0404 11:45:02.289000 54198 site-packages/torch/_dynamo/convert_frame.py:1233]     return function(*args, **kwargs)\n",
      "W0404 11:45:02.289000 54198 site-packages/torch/_dynamo/convert_frame.py:1233]   File \"/opt/anaconda3/envs/cs5388-a1/lib/python3.13/site-packages/torch/_dynamo/convert_frame.py\", line 750, in _compile_inner\n",
      "W0404 11:45:02.289000 54198 site-packages/torch/_dynamo/convert_frame.py:1233]     out_code = transform_code_object(code, transform)\n",
      "W0404 11:45:02.289000 54198 site-packages/torch/_dynamo/convert_frame.py:1233]   File \"/opt/anaconda3/envs/cs5388-a1/lib/python3.13/site-packages/torch/_dynamo/bytecode_transformation.py\", line 1361, in transform_code_object\n",
      "W0404 11:45:02.289000 54198 site-packages/torch/_dynamo/convert_frame.py:1233]     transformations(instructions, code_options)\n",
      "W0404 11:45:02.289000 54198 site-packages/torch/_dynamo/convert_frame.py:1233]     ~~~~~~~~~~~~~~~^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "W0404 11:45:02.289000 54198 site-packages/torch/_dynamo/convert_frame.py:1233]   File \"/opt/anaconda3/envs/cs5388-a1/lib/python3.13/site-packages/torch/_dynamo/convert_frame.py\", line 231, in _fn\n",
      "W0404 11:45:02.289000 54198 site-packages/torch/_dynamo/convert_frame.py:1233]     return fn(*args, **kwargs)\n",
      "W0404 11:45:02.289000 54198 site-packages/torch/_dynamo/convert_frame.py:1233]   File \"/opt/anaconda3/envs/cs5388-a1/lib/python3.13/site-packages/torch/_dynamo/convert_frame.py\", line 662, in transform\n",
      "W0404 11:45:02.289000 54198 site-packages/torch/_dynamo/convert_frame.py:1233]     tracer.run()\n",
      "W0404 11:45:02.289000 54198 site-packages/torch/_dynamo/convert_frame.py:1233]     ~~~~~~~~~~^^\n",
      "W0404 11:45:02.289000 54198 site-packages/torch/_dynamo/convert_frame.py:1233]   File \"/opt/anaconda3/envs/cs5388-a1/lib/python3.13/site-packages/torch/_dynamo/symbolic_convert.py\", line 2868, in run\n",
      "W0404 11:45:02.289000 54198 site-packages/torch/_dynamo/convert_frame.py:1233]     super().run()\n",
      "W0404 11:45:02.289000 54198 site-packages/torch/_dynamo/convert_frame.py:1233]     ~~~~~~~~~~~^^\n",
      "W0404 11:45:02.289000 54198 site-packages/torch/_dynamo/convert_frame.py:1233]   File \"/opt/anaconda3/envs/cs5388-a1/lib/python3.13/site-packages/torch/_dynamo/symbolic_convert.py\", line 1052, in run\n",
      "W0404 11:45:02.289000 54198 site-packages/torch/_dynamo/convert_frame.py:1233]     while self.step():\n",
      "W0404 11:45:02.289000 54198 site-packages/torch/_dynamo/convert_frame.py:1233]           ~~~~~~~~~^^\n",
      "W0404 11:45:02.289000 54198 site-packages/torch/_dynamo/convert_frame.py:1233]   File \"/opt/anaconda3/envs/cs5388-a1/lib/python3.13/site-packages/torch/_dynamo/symbolic_convert.py\", line 962, in step\n",
      "W0404 11:45:02.289000 54198 site-packages/torch/_dynamo/convert_frame.py:1233]     self.dispatch_table[inst.opcode](self, inst)\n",
      "W0404 11:45:02.289000 54198 site-packages/torch/_dynamo/convert_frame.py:1233]     ~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~^^^^^^^^^^^^\n",
      "W0404 11:45:02.289000 54198 site-packages/torch/_dynamo/convert_frame.py:1233]   File \"/opt/anaconda3/envs/cs5388-a1/lib/python3.13/site-packages/torch/_dynamo/symbolic_convert.py\", line 3048, in RETURN_VALUE\n",
      "W0404 11:45:02.289000 54198 site-packages/torch/_dynamo/convert_frame.py:1233]     self._return(inst)\n",
      "W0404 11:45:02.289000 54198 site-packages/torch/_dynamo/convert_frame.py:1233]     ~~~~~~~~~~~~^^^^^^\n",
      "W0404 11:45:02.289000 54198 site-packages/torch/_dynamo/convert_frame.py:1233]   File \"/opt/anaconda3/envs/cs5388-a1/lib/python3.13/site-packages/torch/_dynamo/symbolic_convert.py\", line 3033, in _return\n",
      "W0404 11:45:02.289000 54198 site-packages/torch/_dynamo/convert_frame.py:1233]     self.output.compile_subgraph(\n",
      "W0404 11:45:02.289000 54198 site-packages/torch/_dynamo/convert_frame.py:1233]     ~~~~~~~~~~~~~~~~~~~~~~~~~~~~^\n",
      "W0404 11:45:02.289000 54198 site-packages/torch/_dynamo/convert_frame.py:1233]         self,\n",
      "W0404 11:45:02.289000 54198 site-packages/torch/_dynamo/convert_frame.py:1233]         ^^^^^\n",
      "W0404 11:45:02.289000 54198 site-packages/torch/_dynamo/convert_frame.py:1233]     ...<2 lines>...\n",
      "W0404 11:45:02.289000 54198 site-packages/torch/_dynamo/convert_frame.py:1233]         ),\n",
      "W0404 11:45:02.289000 54198 site-packages/torch/_dynamo/convert_frame.py:1233]         ^^\n",
      "W0404 11:45:02.289000 54198 site-packages/torch/_dynamo/convert_frame.py:1233]     )\n",
      "W0404 11:45:02.289000 54198 site-packages/torch/_dynamo/convert_frame.py:1233]     ^\n",
      "W0404 11:45:02.289000 54198 site-packages/torch/_dynamo/convert_frame.py:1233]   File \"/opt/anaconda3/envs/cs5388-a1/lib/python3.13/site-packages/torch/_dynamo/output_graph.py\", line 1101, in compile_subgraph\n",
      "W0404 11:45:02.289000 54198 site-packages/torch/_dynamo/convert_frame.py:1233]     self.compile_and_call_fx_graph(\n",
      "W0404 11:45:02.289000 54198 site-packages/torch/_dynamo/convert_frame.py:1233]     ~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~^\n",
      "W0404 11:45:02.289000 54198 site-packages/torch/_dynamo/convert_frame.py:1233]         tx, list(reversed(stack_values)), root, output_replacements\n",
      "W0404 11:45:02.289000 54198 site-packages/torch/_dynamo/convert_frame.py:1233]         ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "W0404 11:45:02.289000 54198 site-packages/torch/_dynamo/convert_frame.py:1233]     )\n",
      "W0404 11:45:02.289000 54198 site-packages/torch/_dynamo/convert_frame.py:1233]     ^\n",
      "W0404 11:45:02.289000 54198 site-packages/torch/_dynamo/convert_frame.py:1233]   File \"/opt/anaconda3/envs/cs5388-a1/lib/python3.13/site-packages/torch/_dynamo/output_graph.py\", line 1382, in compile_and_call_fx_graph\n",
      "W0404 11:45:02.289000 54198 site-packages/torch/_dynamo/convert_frame.py:1233]     compiled_fn = self.call_user_compiler(gm)\n",
      "W0404 11:45:02.289000 54198 site-packages/torch/_dynamo/convert_frame.py:1233]   File \"/opt/anaconda3/envs/cs5388-a1/lib/python3.13/site-packages/torch/_dynamo/output_graph.py\", line 1432, in call_user_compiler\n",
      "W0404 11:45:02.289000 54198 site-packages/torch/_dynamo/convert_frame.py:1233]     return self._call_user_compiler(gm)\n",
      "W0404 11:45:02.289000 54198 site-packages/torch/_dynamo/convert_frame.py:1233]            ~~~~~~~~~~~~~~~~~~~~~~~~^^^^\n",
      "W0404 11:45:02.289000 54198 site-packages/torch/_dynamo/convert_frame.py:1233]   File \"/opt/anaconda3/envs/cs5388-a1/lib/python3.13/site-packages/torch/_dynamo/output_graph.py\", line 1483, in _call_user_compiler\n",
      "W0404 11:45:02.289000 54198 site-packages/torch/_dynamo/convert_frame.py:1233]     raise BackendCompilerFailed(self.compiler_fn, e).with_traceback(\n",
      "W0404 11:45:02.289000 54198 site-packages/torch/_dynamo/convert_frame.py:1233]         e.__traceback__\n",
      "W0404 11:45:02.289000 54198 site-packages/torch/_dynamo/convert_frame.py:1233]     ) from None\n",
      "W0404 11:45:02.289000 54198 site-packages/torch/_dynamo/convert_frame.py:1233]   File \"/opt/anaconda3/envs/cs5388-a1/lib/python3.13/site-packages/torch/_dynamo/output_graph.py\", line 1462, in _call_user_compiler\n",
      "W0404 11:45:02.289000 54198 site-packages/torch/_dynamo/convert_frame.py:1233]     compiled_fn = compiler_fn(gm, self.example_inputs())\n",
      "W0404 11:45:02.289000 54198 site-packages/torch/_dynamo/convert_frame.py:1233]   File \"/opt/anaconda3/envs/cs5388-a1/lib/python3.13/site-packages/torch/_dynamo/repro/after_dynamo.py\", line 130, in __call__\n",
      "W0404 11:45:02.289000 54198 site-packages/torch/_dynamo/convert_frame.py:1233]     compiled_gm = compiler_fn(gm, example_inputs)\n",
      "W0404 11:45:02.289000 54198 site-packages/torch/_dynamo/convert_frame.py:1233]   File \"/opt/anaconda3/envs/cs5388-a1/lib/python3.13/site-packages/torch/__init__.py\", line 2340, in __call__\n",
      "W0404 11:45:02.289000 54198 site-packages/torch/_dynamo/convert_frame.py:1233]     return compile_fx(model_, inputs_, config_patches=self.config)\n",
      "W0404 11:45:02.289000 54198 site-packages/torch/_dynamo/convert_frame.py:1233]   File \"/opt/anaconda3/envs/cs5388-a1/lib/python3.13/site-packages/torch/_inductor/compile_fx.py\", line 1863, in compile_fx\n",
      "W0404 11:45:02.289000 54198 site-packages/torch/_dynamo/convert_frame.py:1233]     return aot_autograd(\n",
      "W0404 11:45:02.289000 54198 site-packages/torch/_dynamo/convert_frame.py:1233]            ~~~~~~~~~~~~~\n",
      "W0404 11:45:02.289000 54198 site-packages/torch/_dynamo/convert_frame.py:1233]     ...<6 lines>...\n",
      "W0404 11:45:02.289000 54198 site-packages/torch/_dynamo/convert_frame.py:1233]         cudagraphs=cudagraphs,\n",
      "W0404 11:45:02.289000 54198 site-packages/torch/_dynamo/convert_frame.py:1233]         ~~~~~~~~~~~~~~~~~~~~~~\n",
      "W0404 11:45:02.289000 54198 site-packages/torch/_dynamo/convert_frame.py:1233]     )(model_, example_inputs_)\n",
      "W0404 11:45:02.289000 54198 site-packages/torch/_dynamo/convert_frame.py:1233]     ~^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "W0404 11:45:02.289000 54198 site-packages/torch/_dynamo/convert_frame.py:1233]   File \"/opt/anaconda3/envs/cs5388-a1/lib/python3.13/site-packages/torch/_dynamo/backends/common.py\", line 83, in __call__\n",
      "W0404 11:45:02.289000 54198 site-packages/torch/_dynamo/convert_frame.py:1233]     cg = aot_module_simplified(gm, example_inputs, **self.kwargs)\n",
      "W0404 11:45:02.289000 54198 site-packages/torch/_dynamo/convert_frame.py:1233]   File \"/opt/anaconda3/envs/cs5388-a1/lib/python3.13/site-packages/torch/_functorch/aot_autograd.py\", line 1155, in aot_module_simplified\n",
      "W0404 11:45:02.289000 54198 site-packages/torch/_dynamo/convert_frame.py:1233]     compiled_fn = dispatch_and_compile()\n",
      "W0404 11:45:02.289000 54198 site-packages/torch/_dynamo/convert_frame.py:1233]   File \"/opt/anaconda3/envs/cs5388-a1/lib/python3.13/site-packages/torch/_functorch/aot_autograd.py\", line 1131, in dispatch_and_compile\n",
      "W0404 11:45:02.289000 54198 site-packages/torch/_dynamo/convert_frame.py:1233]     compiled_fn, _ = create_aot_dispatcher_function(\n",
      "W0404 11:45:02.289000 54198 site-packages/torch/_dynamo/convert_frame.py:1233]                      ~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~^\n",
      "W0404 11:45:02.289000 54198 site-packages/torch/_dynamo/convert_frame.py:1233]         functional_call,\n",
      "W0404 11:45:02.289000 54198 site-packages/torch/_dynamo/convert_frame.py:1233]         ^^^^^^^^^^^^^^^^\n",
      "W0404 11:45:02.289000 54198 site-packages/torch/_dynamo/convert_frame.py:1233]     ...<3 lines>...\n",
      "W0404 11:45:02.289000 54198 site-packages/torch/_dynamo/convert_frame.py:1233]         shape_env,\n",
      "W0404 11:45:02.289000 54198 site-packages/torch/_dynamo/convert_frame.py:1233]         ^^^^^^^^^^\n",
      "W0404 11:45:02.289000 54198 site-packages/torch/_dynamo/convert_frame.py:1233]     )\n",
      "W0404 11:45:02.289000 54198 site-packages/torch/_dynamo/convert_frame.py:1233]     ^\n",
      "W0404 11:45:02.289000 54198 site-packages/torch/_dynamo/convert_frame.py:1233]   File \"/opt/anaconda3/envs/cs5388-a1/lib/python3.13/site-packages/torch/_functorch/aot_autograd.py\", line 580, in create_aot_dispatcher_function\n",
      "W0404 11:45:02.289000 54198 site-packages/torch/_dynamo/convert_frame.py:1233]     return _create_aot_dispatcher_function(\n",
      "W0404 11:45:02.289000 54198 site-packages/torch/_dynamo/convert_frame.py:1233]         flat_fn, fake_flat_args, aot_config, fake_mode, shape_env\n",
      "W0404 11:45:02.289000 54198 site-packages/torch/_dynamo/convert_frame.py:1233]     )\n",
      "W0404 11:45:02.289000 54198 site-packages/torch/_dynamo/convert_frame.py:1233]   File \"/opt/anaconda3/envs/cs5388-a1/lib/python3.13/site-packages/torch/_functorch/aot_autograd.py\", line 830, in _create_aot_dispatcher_function\n",
      "W0404 11:45:02.289000 54198 site-packages/torch/_dynamo/convert_frame.py:1233]     compiled_fn, fw_metadata = compiler_fn(\n",
      "W0404 11:45:02.289000 54198 site-packages/torch/_dynamo/convert_frame.py:1233]                                ~~~~~~~~~~~^\n",
      "W0404 11:45:02.289000 54198 site-packages/torch/_dynamo/convert_frame.py:1233]         flat_fn,\n",
      "W0404 11:45:02.289000 54198 site-packages/torch/_dynamo/convert_frame.py:1233]         ^^^^^^^^\n",
      "W0404 11:45:02.289000 54198 site-packages/torch/_dynamo/convert_frame.py:1233]     ...<2 lines>...\n",
      "W0404 11:45:02.289000 54198 site-packages/torch/_dynamo/convert_frame.py:1233]         fw_metadata=fw_metadata,\n",
      "W0404 11:45:02.289000 54198 site-packages/torch/_dynamo/convert_frame.py:1233]         ^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "W0404 11:45:02.289000 54198 site-packages/torch/_dynamo/convert_frame.py:1233]     )\n",
      "W0404 11:45:02.289000 54198 site-packages/torch/_dynamo/convert_frame.py:1233]     ^\n",
      "W0404 11:45:02.289000 54198 site-packages/torch/_dynamo/convert_frame.py:1233]   File \"/opt/anaconda3/envs/cs5388-a1/lib/python3.13/site-packages/torch/_functorch/_aot_autograd/jit_compile_runtime_wrappers.py\", line 678, in aot_dispatch_autograd\n",
      "W0404 11:45:02.289000 54198 site-packages/torch/_dynamo/convert_frame.py:1233]     compiled_fw_func = aot_config.fw_compiler(fw_module, adjusted_flat_args)\n",
      "W0404 11:45:02.289000 54198 site-packages/torch/_dynamo/convert_frame.py:1233]   File \"/opt/anaconda3/envs/cs5388-a1/lib/python3.13/site-packages/torch/_functorch/aot_autograd.py\", line 489, in __call__\n",
      "W0404 11:45:02.289000 54198 site-packages/torch/_dynamo/convert_frame.py:1233]     return self.compiler_fn(gm, example_inputs)\n",
      "W0404 11:45:02.289000 54198 site-packages/torch/_dynamo/convert_frame.py:1233]            ~~~~~~~~~~~~~~~~^^^^^^^^^^^^^^^^^^^^\n",
      "W0404 11:45:02.289000 54198 site-packages/torch/_dynamo/convert_frame.py:1233]   File \"/opt/anaconda3/envs/cs5388-a1/lib/python3.13/site-packages/torch/_inductor/compile_fx.py\", line 1741, in fw_compiler_base\n",
      "W0404 11:45:02.289000 54198 site-packages/torch/_dynamo/convert_frame.py:1233]     return inner_compile(\n",
      "W0404 11:45:02.289000 54198 site-packages/torch/_dynamo/convert_frame.py:1233]         gm,\n",
      "W0404 11:45:02.289000 54198 site-packages/torch/_dynamo/convert_frame.py:1233]     ...<5 lines>...\n",
      "W0404 11:45:02.289000 54198 site-packages/torch/_dynamo/convert_frame.py:1233]         boxed_forward_device_index=forward_device,\n",
      "W0404 11:45:02.289000 54198 site-packages/torch/_dynamo/convert_frame.py:1233]     )\n",
      "W0404 11:45:02.289000 54198 site-packages/torch/_dynamo/convert_frame.py:1233]   File \"/opt/anaconda3/envs/cs5388-a1/lib/python3.13/site-packages/torch/_inductor/compile_fx.py\", line 569, in compile_fx_inner\n",
      "W0404 11:45:02.289000 54198 site-packages/torch/_dynamo/convert_frame.py:1233]     return wrap_compiler_debug(_compile_fx_inner, compiler_name=\"inductor\")(\n",
      "W0404 11:45:02.289000 54198 site-packages/torch/_dynamo/convert_frame.py:1233]            ~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~^\n",
      "W0404 11:45:02.289000 54198 site-packages/torch/_dynamo/convert_frame.py:1233]         gm,\n",
      "W0404 11:45:02.289000 54198 site-packages/torch/_dynamo/convert_frame.py:1233]         ^^^\n",
      "W0404 11:45:02.289000 54198 site-packages/torch/_dynamo/convert_frame.py:1233]         example_inputs,\n",
      "W0404 11:45:02.289000 54198 site-packages/torch/_dynamo/convert_frame.py:1233]         ^^^^^^^^^^^^^^^\n",
      "W0404 11:45:02.289000 54198 site-packages/torch/_dynamo/convert_frame.py:1233]         **kwargs,\n",
      "W0404 11:45:02.289000 54198 site-packages/torch/_dynamo/convert_frame.py:1233]         ^^^^^^^^^\n",
      "W0404 11:45:02.289000 54198 site-packages/torch/_dynamo/convert_frame.py:1233]     )\n",
      "W0404 11:45:02.289000 54198 site-packages/torch/_dynamo/convert_frame.py:1233]     ^\n",
      "W0404 11:45:02.289000 54198 site-packages/torch/_dynamo/convert_frame.py:1233]   File \"/opt/anaconda3/envs/cs5388-a1/lib/python3.13/site-packages/torch/_dynamo/repro/after_aot.py\", line 102, in debug_wrapper\n",
      "W0404 11:45:02.289000 54198 site-packages/torch/_dynamo/convert_frame.py:1233]     inner_compiled_fn = compiler_fn(gm, example_inputs)\n",
      "W0404 11:45:02.289000 54198 site-packages/torch/_dynamo/convert_frame.py:1233]   File \"/opt/anaconda3/envs/cs5388-a1/lib/python3.13/site-packages/torch/_inductor/compile_fx.py\", line 685, in _compile_fx_inner\n",
      "W0404 11:45:02.289000 54198 site-packages/torch/_dynamo/convert_frame.py:1233]     mb_compiled_graph = fx_codegen_and_compile(\n",
      "W0404 11:45:02.289000 54198 site-packages/torch/_dynamo/convert_frame.py:1233]         gm, example_inputs, inputs_to_check, **graph_kwargs\n",
      "W0404 11:45:02.289000 54198 site-packages/torch/_dynamo/convert_frame.py:1233]     )\n",
      "W0404 11:45:02.289000 54198 site-packages/torch/_dynamo/convert_frame.py:1233]   File \"/opt/anaconda3/envs/cs5388-a1/lib/python3.13/site-packages/torch/_inductor/compile_fx.py\", line 1129, in fx_codegen_and_compile\n",
      "W0404 11:45:02.289000 54198 site-packages/torch/_dynamo/convert_frame.py:1233]     return scheme.codegen_and_compile(gm, example_inputs, inputs_to_check, graph_kwargs)\n",
      "W0404 11:45:02.289000 54198 site-packages/torch/_dynamo/convert_frame.py:1233]            ~~~~~~~~~~~~~~~~~~~~~~~~~~^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "W0404 11:45:02.289000 54198 site-packages/torch/_dynamo/convert_frame.py:1233]   File \"/opt/anaconda3/envs/cs5388-a1/lib/python3.13/site-packages/torch/_inductor/compile_fx.py\", line 1044, in codegen_and_compile\n",
      "W0404 11:45:02.289000 54198 site-packages/torch/_dynamo/convert_frame.py:1233]     compiled_fn = graph.compile_to_module().call\n",
      "W0404 11:45:02.289000 54198 site-packages/torch/_dynamo/convert_frame.py:1233]                   ~~~~~~~~~~~~~~~~~~~~~~~^^\n",
      "W0404 11:45:02.289000 54198 site-packages/torch/_dynamo/convert_frame.py:1233]   File \"/opt/anaconda3/envs/cs5388-a1/lib/python3.13/site-packages/torch/_inductor/graph.py\", line 2027, in compile_to_module\n",
      "W0404 11:45:02.289000 54198 site-packages/torch/_dynamo/convert_frame.py:1233]     return self._compile_to_module()\n",
      "W0404 11:45:02.289000 54198 site-packages/torch/_dynamo/convert_frame.py:1233]            ~~~~~~~~~~~~~~~~~~~~~~~^^\n",
      "W0404 11:45:02.289000 54198 site-packages/torch/_dynamo/convert_frame.py:1233]   File \"/opt/anaconda3/envs/cs5388-a1/lib/python3.13/site-packages/torch/_inductor/graph.py\", line 2033, in _compile_to_module\n",
      "W0404 11:45:02.289000 54198 site-packages/torch/_dynamo/convert_frame.py:1233]     self.codegen_with_cpp_wrapper() if self.cpp_wrapper else self.codegen()\n",
      "W0404 11:45:02.289000 54198 site-packages/torch/_dynamo/convert_frame.py:1233]                                                              ~~~~~~~~~~~~^^\n",
      "W0404 11:45:02.289000 54198 site-packages/torch/_dynamo/convert_frame.py:1233]   File \"/opt/anaconda3/envs/cs5388-a1/lib/python3.13/site-packages/torch/_inductor/graph.py\", line 1968, in codegen\n",
      "W0404 11:45:02.289000 54198 site-packages/torch/_dynamo/convert_frame.py:1233]     self.scheduler.codegen()\n",
      "W0404 11:45:02.289000 54198 site-packages/torch/_dynamo/convert_frame.py:1233]     ~~~~~~~~~~~~~~~~~~~~~~^^\n",
      "W0404 11:45:02.289000 54198 site-packages/torch/_dynamo/convert_frame.py:1233]   File \"/opt/anaconda3/envs/cs5388-a1/lib/python3.13/site-packages/torch/_inductor/scheduler.py\", line 3477, in codegen\n",
      "W0404 11:45:02.289000 54198 site-packages/torch/_dynamo/convert_frame.py:1233]     return self._codegen()\n",
      "W0404 11:45:02.289000 54198 site-packages/torch/_dynamo/convert_frame.py:1233]            ~~~~~~~~~~~~~^^\n",
      "W0404 11:45:02.289000 54198 site-packages/torch/_dynamo/convert_frame.py:1233]   File \"/opt/anaconda3/envs/cs5388-a1/lib/python3.13/site-packages/torch/_inductor/scheduler.py\", line 3554, in _codegen\n",
      "W0404 11:45:02.289000 54198 site-packages/torch/_dynamo/convert_frame.py:1233]     self.get_backend(device).codegen_node(node)\n",
      "W0404 11:45:02.289000 54198 site-packages/torch/_dynamo/convert_frame.py:1233]     ~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~^^^^^^\n",
      "W0404 11:45:02.289000 54198 site-packages/torch/_dynamo/convert_frame.py:1233]   File \"/opt/anaconda3/envs/cs5388-a1/lib/python3.13/site-packages/torch/_inductor/codegen/cpp.py\", line 4782, in codegen_node\n",
      "W0404 11:45:02.289000 54198 site-packages/torch/_dynamo/convert_frame.py:1233]     cpp_kernel_proxy.codegen_nodes(nodes)\n",
      "W0404 11:45:02.289000 54198 site-packages/torch/_dynamo/convert_frame.py:1233]     ~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~^^^^^^^\n",
      "W0404 11:45:02.289000 54198 site-packages/torch/_dynamo/convert_frame.py:1233]   File \"/opt/anaconda3/envs/cs5388-a1/lib/python3.13/site-packages/torch/_inductor/codegen/cpp.py\", line 4044, in codegen_nodes\n",
      "W0404 11:45:02.289000 54198 site-packages/torch/_dynamo/convert_frame.py:1233]     self.codegen_functions(fn_list, var_sizes_list)\n",
      "W0404 11:45:02.289000 54198 site-packages/torch/_dynamo/convert_frame.py:1233]     ~~~~~~~~~~~~~~~~~~~~~~^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "W0404 11:45:02.289000 54198 site-packages/torch/_dynamo/convert_frame.py:1233]   File \"/opt/anaconda3/envs/cs5388-a1/lib/python3.13/site-packages/torch/_inductor/codegen/cpp.py\", line 3862, in codegen_functions\n",
      "W0404 11:45:02.289000 54198 site-packages/torch/_dynamo/convert_frame.py:1233]     self.loop_nest = LoopNest.build(scalar_kernel)\n",
      "W0404 11:45:02.289000 54198 site-packages/torch/_dynamo/convert_frame.py:1233]                      ~~~~~~~~~~~~~~^^^^^^^^^^^^^^^\n",
      "W0404 11:45:02.289000 54198 site-packages/torch/_dynamo/convert_frame.py:1233]   File \"/opt/anaconda3/envs/cs5388-a1/lib/python3.13/site-packages/torch/_inductor/codegen/cpp.py\", line 5124, in build\n",
      "W0404 11:45:02.289000 54198 site-packages/torch/_dynamo/convert_frame.py:1233]     loop = LoopLevel(var, size)\n",
      "W0404 11:45:02.289000 54198 site-packages/torch/_dynamo/convert_frame.py:1233]   File \"<string>\", line 13, in __init__\n",
      "W0404 11:45:02.289000 54198 site-packages/torch/_dynamo/convert_frame.py:1233]   File \"/opt/anaconda3/envs/cs5388-a1/lib/python3.13/site-packages/torch/_inductor/codegen/cpp.py\", line 5045, in __post_init__\n",
      "W0404 11:45:02.289000 54198 site-packages/torch/_dynamo/convert_frame.py:1233]     self.simd_nelements: int = picked_vec_isa.nelements() if picked_vec_isa else 0\n",
      "W0404 11:45:02.289000 54198 site-packages/torch/_dynamo/convert_frame.py:1233]                                                              ^^^^^^^^^^^^^^\n",
      "W0404 11:45:02.289000 54198 site-packages/torch/_dynamo/convert_frame.py:1233]   File \"/opt/anaconda3/envs/cs5388-a1/lib/python3.13/site-packages/torch/_inductor/cpu_vec_isa.py\", line 142, in __bool__\n",
      "W0404 11:45:02.289000 54198 site-packages/torch/_dynamo/convert_frame.py:1233]     return self.__bool__impl(config.cpp.vec_isa_ok)\n",
      "W0404 11:45:02.289000 54198 site-packages/torch/_dynamo/convert_frame.py:1233]            ~~~~~~~~~~~~~~~~~^^^^^^^^^^^^^^^^^^^^^^^\n",
      "W0404 11:45:02.289000 54198 site-packages/torch/_dynamo/convert_frame.py:1233]   File \"/opt/anaconda3/envs/cs5388-a1/lib/python3.13/site-packages/torch/_inductor/cpu_vec_isa.py\", line 152, in __bool__impl\n",
      "W0404 11:45:02.289000 54198 site-packages/torch/_dynamo/convert_frame.py:1233]     return self.check_build(VecISA._avx_code)\n",
      "W0404 11:45:02.289000 54198 site-packages/torch/_dynamo/convert_frame.py:1233]            ~~~~~~~~~~~~~~~~^^^^^^^^^^^^^^^^^^\n",
      "W0404 11:45:02.289000 54198 site-packages/torch/_dynamo/convert_frame.py:1233]   File \"/opt/anaconda3/envs/cs5388-a1/lib/python3.13/site-packages/torch/_inductor/cpu_vec_isa.py\", line 102, in check_build\n",
      "W0404 11:45:02.289000 54198 site-packages/torch/_dynamo/convert_frame.py:1233]     extra=_get_isa_dry_compile_fingerprint(self._arch_flags),\n",
      "W0404 11:45:02.289000 54198 site-packages/torch/_dynamo/convert_frame.py:1233]           ~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~^^^^^^^^^^^^^^^^^^\n",
      "W0404 11:45:02.289000 54198 site-packages/torch/_dynamo/convert_frame.py:1233]   File \"/opt/anaconda3/envs/cs5388-a1/lib/python3.13/site-packages/torch/_inductor/cpu_vec_isa.py\", line 28, in _get_isa_dry_compile_fingerprint\n",
      "W0404 11:45:02.289000 54198 site-packages/torch/_dynamo/convert_frame.py:1233]     compiler_info = get_compiler_version_info(get_cpp_compiler())\n",
      "W0404 11:45:02.289000 54198 site-packages/torch/_dynamo/convert_frame.py:1233]                                               ~~~~~~~~~~~~~~~~^^\n",
      "W0404 11:45:02.289000 54198 site-packages/torch/_dynamo/convert_frame.py:1233]   File \"/opt/anaconda3/envs/cs5388-a1/lib/python3.13/site-packages/torch/_inductor/cpp_builder.py\", line 152, in get_cpp_compiler\n",
      "W0404 11:45:02.289000 54198 site-packages/torch/_dynamo/convert_frame.py:1233]     compiler = cpp_compiler_search(search)\n",
      "W0404 11:45:02.289000 54198 site-packages/torch/_dynamo/convert_frame.py:1233]   File \"/opt/anaconda3/envs/cs5388-a1/lib/python3.13/site-packages/torch/_inductor/cpp_builder.py\", line 94, in cpp_compiler_search\n",
      "W0404 11:45:02.289000 54198 site-packages/torch/_dynamo/convert_frame.py:1233]     raise exc.InvalidCxxCompiler\n",
      "W0404 11:45:02.289000 54198 site-packages/torch/_dynamo/convert_frame.py:1233] torch._dynamo.exc.BackendCompilerFailed: backend='inductor' raised:\n",
      "W0404 11:45:02.289000 54198 site-packages/torch/_dynamo/convert_frame.py:1233] InvalidCxxCompiler: No working C++ compiler found in torch._inductor.config.cpp.cxx: (None, 'arm64-apple-darwin20.0.0-clang++')\n",
      "W0404 11:45:02.289000 54198 site-packages/torch/_dynamo/convert_frame.py:1233] \n",
      "W0404 11:45:02.289000 54198 site-packages/torch/_dynamo/convert_frame.py:1233] Set TORCH_LOGS=\"+dynamo\" and TORCHDYNAMO_VERBOSE=1 for more information\n",
      "W0404 11:45:02.289000 54198 site-packages/torch/_dynamo/convert_frame.py:1233] \n",
      "W0404 11:45:02.289000 54198 site-packages/torch/_dynamo/convert_frame.py:1233] Traceback (most recent call last):\n",
      "W0404 11:45:02.289000 54198 site-packages/torch/_dynamo/convert_frame.py:1233]   File \"/opt/anaconda3/envs/cs5388-a1/lib/python3.13/site-packages/torch/_dynamo/convert_frame.py\", line 1164, in __call__\n",
      "W0404 11:45:02.289000 54198 site-packages/torch/_dynamo/convert_frame.py:1233]     result = self._inner_convert(\n",
      "W0404 11:45:02.289000 54198 site-packages/torch/_dynamo/convert_frame.py:1233]         frame, cache_entry, hooks, frame_state, skip=skip + 1\n",
      "W0404 11:45:02.289000 54198 site-packages/torch/_dynamo/convert_frame.py:1233]     )\n",
      "W0404 11:45:02.289000 54198 site-packages/torch/_dynamo/convert_frame.py:1233]   File \"/opt/anaconda3/envs/cs5388-a1/lib/python3.13/site-packages/torch/_dynamo/convert_frame.py\", line 547, in __call__\n",
      "W0404 11:45:02.289000 54198 site-packages/torch/_dynamo/convert_frame.py:1233]     return _compile(\n",
      "W0404 11:45:02.289000 54198 site-packages/torch/_dynamo/convert_frame.py:1233]         frame.f_code,\n",
      "W0404 11:45:02.289000 54198 site-packages/torch/_dynamo/convert_frame.py:1233]     ...<14 lines>...\n",
      "W0404 11:45:02.289000 54198 site-packages/torch/_dynamo/convert_frame.py:1233]         skip=skip + 1,\n",
      "W0404 11:45:02.289000 54198 site-packages/torch/_dynamo/convert_frame.py:1233]     )\n",
      "W0404 11:45:02.289000 54198 site-packages/torch/_dynamo/convert_frame.py:1233]   File \"/opt/anaconda3/envs/cs5388-a1/lib/python3.13/site-packages/torch/_dynamo/convert_frame.py\", line 986, in _compile\n",
      "W0404 11:45:02.289000 54198 site-packages/torch/_dynamo/convert_frame.py:1233]     guarded_code = compile_inner(code, one_graph, hooks, transform)\n",
      "W0404 11:45:02.289000 54198 site-packages/torch/_dynamo/convert_frame.py:1233]   File \"/opt/anaconda3/envs/cs5388-a1/lib/python3.13/site-packages/torch/_dynamo/convert_frame.py\", line 715, in compile_inner\n",
      "W0404 11:45:02.289000 54198 site-packages/torch/_dynamo/convert_frame.py:1233]     return _compile_inner(code, one_graph, hooks, transform)\n",
      "W0404 11:45:02.289000 54198 site-packages/torch/_dynamo/convert_frame.py:1233]   File \"/opt/anaconda3/envs/cs5388-a1/lib/python3.13/site-packages/torch/_utils_internal.py\", line 95, in wrapper_function\n",
      "W0404 11:45:02.289000 54198 site-packages/torch/_dynamo/convert_frame.py:1233]     return function(*args, **kwargs)\n",
      "W0404 11:45:02.289000 54198 site-packages/torch/_dynamo/convert_frame.py:1233]   File \"/opt/anaconda3/envs/cs5388-a1/lib/python3.13/site-packages/torch/_dynamo/convert_frame.py\", line 750, in _compile_inner\n",
      "W0404 11:45:02.289000 54198 site-packages/torch/_dynamo/convert_frame.py:1233]     out_code = transform_code_object(code, transform)\n",
      "W0404 11:45:02.289000 54198 site-packages/torch/_dynamo/convert_frame.py:1233]   File \"/opt/anaconda3/envs/cs5388-a1/lib/python3.13/site-packages/torch/_dynamo/bytecode_transformation.py\", line 1361, in transform_code_object\n",
      "W0404 11:45:02.289000 54198 site-packages/torch/_dynamo/convert_frame.py:1233]     transformations(instructions, code_options)\n",
      "W0404 11:45:02.289000 54198 site-packages/torch/_dynamo/convert_frame.py:1233]     ~~~~~~~~~~~~~~~^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "W0404 11:45:02.289000 54198 site-packages/torch/_dynamo/convert_frame.py:1233]   File \"/opt/anaconda3/envs/cs5388-a1/lib/python3.13/site-packages/torch/_dynamo/convert_frame.py\", line 231, in _fn\n",
      "W0404 11:45:02.289000 54198 site-packages/torch/_dynamo/convert_frame.py:1233]     return fn(*args, **kwargs)\n",
      "W0404 11:45:02.289000 54198 site-packages/torch/_dynamo/convert_frame.py:1233]   File \"/opt/anaconda3/envs/cs5388-a1/lib/python3.13/site-packages/torch/_dynamo/convert_frame.py\", line 662, in transform\n",
      "W0404 11:45:02.289000 54198 site-packages/torch/_dynamo/convert_frame.py:1233]     tracer.run()\n",
      "W0404 11:45:02.289000 54198 site-packages/torch/_dynamo/convert_frame.py:1233]     ~~~~~~~~~~^^\n",
      "W0404 11:45:02.289000 54198 site-packages/torch/_dynamo/convert_frame.py:1233]   File \"/opt/anaconda3/envs/cs5388-a1/lib/python3.13/site-packages/torch/_dynamo/symbolic_convert.py\", line 2868, in run\n",
      "W0404 11:45:02.289000 54198 site-packages/torch/_dynamo/convert_frame.py:1233]     super().run()\n",
      "W0404 11:45:02.289000 54198 site-packages/torch/_dynamo/convert_frame.py:1233]     ~~~~~~~~~~~^^\n",
      "W0404 11:45:02.289000 54198 site-packages/torch/_dynamo/convert_frame.py:1233]   File \"/opt/anaconda3/envs/cs5388-a1/lib/python3.13/site-packages/torch/_dynamo/symbolic_convert.py\", line 1052, in run\n",
      "W0404 11:45:02.289000 54198 site-packages/torch/_dynamo/convert_frame.py:1233]     while self.step():\n",
      "W0404 11:45:02.289000 54198 site-packages/torch/_dynamo/convert_frame.py:1233]           ~~~~~~~~~^^\n",
      "W0404 11:45:02.289000 54198 site-packages/torch/_dynamo/convert_frame.py:1233]   File \"/opt/anaconda3/envs/cs5388-a1/lib/python3.13/site-packages/torch/_dynamo/symbolic_convert.py\", line 962, in step\n",
      "W0404 11:45:02.289000 54198 site-packages/torch/_dynamo/convert_frame.py:1233]     self.dispatch_table[inst.opcode](self, inst)\n",
      "W0404 11:45:02.289000 54198 site-packages/torch/_dynamo/convert_frame.py:1233]     ~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~^^^^^^^^^^^^\n",
      "W0404 11:45:02.289000 54198 site-packages/torch/_dynamo/convert_frame.py:1233]   File \"/opt/anaconda3/envs/cs5388-a1/lib/python3.13/site-packages/torch/_dynamo/symbolic_convert.py\", line 3048, in RETURN_VALUE\n",
      "W0404 11:45:02.289000 54198 site-packages/torch/_dynamo/convert_frame.py:1233]     self._return(inst)\n",
      "W0404 11:45:02.289000 54198 site-packages/torch/_dynamo/convert_frame.py:1233]     ~~~~~~~~~~~~^^^^^^\n",
      "W0404 11:45:02.289000 54198 site-packages/torch/_dynamo/convert_frame.py:1233]   File \"/opt/anaconda3/envs/cs5388-a1/lib/python3.13/site-packages/torch/_dynamo/symbolic_convert.py\", line 3033, in _return\n",
      "W0404 11:45:02.289000 54198 site-packages/torch/_dynamo/convert_frame.py:1233]     self.output.compile_subgraph(\n",
      "W0404 11:45:02.289000 54198 site-packages/torch/_dynamo/convert_frame.py:1233]     ~~~~~~~~~~~~~~~~~~~~~~~~~~~~^\n",
      "W0404 11:45:02.289000 54198 site-packages/torch/_dynamo/convert_frame.py:1233]         self,\n",
      "W0404 11:45:02.289000 54198 site-packages/torch/_dynamo/convert_frame.py:1233]         ^^^^^\n",
      "W0404 11:45:02.289000 54198 site-packages/torch/_dynamo/convert_frame.py:1233]     ...<2 lines>...\n",
      "W0404 11:45:02.289000 54198 site-packages/torch/_dynamo/convert_frame.py:1233]         ),\n",
      "W0404 11:45:02.289000 54198 site-packages/torch/_dynamo/convert_frame.py:1233]         ^^\n",
      "W0404 11:45:02.289000 54198 site-packages/torch/_dynamo/convert_frame.py:1233]     )\n",
      "W0404 11:45:02.289000 54198 site-packages/torch/_dynamo/convert_frame.py:1233]     ^\n",
      "W0404 11:45:02.289000 54198 site-packages/torch/_dynamo/convert_frame.py:1233]   File \"/opt/anaconda3/envs/cs5388-a1/lib/python3.13/site-packages/torch/_dynamo/output_graph.py\", line 1101, in compile_subgraph\n",
      "W0404 11:45:02.289000 54198 site-packages/torch/_dynamo/convert_frame.py:1233]     self.compile_and_call_fx_graph(\n",
      "W0404 11:45:02.289000 54198 site-packages/torch/_dynamo/convert_frame.py:1233]     ~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~^\n",
      "W0404 11:45:02.289000 54198 site-packages/torch/_dynamo/convert_frame.py:1233]         tx, list(reversed(stack_values)), root, output_replacements\n",
      "W0404 11:45:02.289000 54198 site-packages/torch/_dynamo/convert_frame.py:1233]         ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "W0404 11:45:02.289000 54198 site-packages/torch/_dynamo/convert_frame.py:1233]     )\n",
      "W0404 11:45:02.289000 54198 site-packages/torch/_dynamo/convert_frame.py:1233]     ^\n",
      "W0404 11:45:02.289000 54198 site-packages/torch/_dynamo/convert_frame.py:1233]   File \"/opt/anaconda3/envs/cs5388-a1/lib/python3.13/site-packages/torch/_dynamo/output_graph.py\", line 1382, in compile_and_call_fx_graph\n",
      "W0404 11:45:02.289000 54198 site-packages/torch/_dynamo/convert_frame.py:1233]     compiled_fn = self.call_user_compiler(gm)\n",
      "W0404 11:45:02.289000 54198 site-packages/torch/_dynamo/convert_frame.py:1233]   File \"/opt/anaconda3/envs/cs5388-a1/lib/python3.13/site-packages/torch/_dynamo/output_graph.py\", line 1432, in call_user_compiler\n",
      "W0404 11:45:02.289000 54198 site-packages/torch/_dynamo/convert_frame.py:1233]     return self._call_user_compiler(gm)\n",
      "W0404 11:45:02.289000 54198 site-packages/torch/_dynamo/convert_frame.py:1233]            ~~~~~~~~~~~~~~~~~~~~~~~~^^^^\n",
      "W0404 11:45:02.289000 54198 site-packages/torch/_dynamo/convert_frame.py:1233]   File \"/opt/anaconda3/envs/cs5388-a1/lib/python3.13/site-packages/torch/_dynamo/output_graph.py\", line 1483, in _call_user_compiler\n",
      "W0404 11:45:02.289000 54198 site-packages/torch/_dynamo/convert_frame.py:1233]     raise BackendCompilerFailed(self.compiler_fn, e).with_traceback(\n",
      "W0404 11:45:02.289000 54198 site-packages/torch/_dynamo/convert_frame.py:1233]         e.__traceback__\n",
      "W0404 11:45:02.289000 54198 site-packages/torch/_dynamo/convert_frame.py:1233]     ) from None\n",
      "W0404 11:45:02.289000 54198 site-packages/torch/_dynamo/convert_frame.py:1233]   File \"/opt/anaconda3/envs/cs5388-a1/lib/python3.13/site-packages/torch/_dynamo/output_graph.py\", line 1462, in _call_user_compiler\n",
      "W0404 11:45:02.289000 54198 site-packages/torch/_dynamo/convert_frame.py:1233]     compiled_fn = compiler_fn(gm, self.example_inputs())\n",
      "W0404 11:45:02.289000 54198 site-packages/torch/_dynamo/convert_frame.py:1233]   File \"/opt/anaconda3/envs/cs5388-a1/lib/python3.13/site-packages/torch/_dynamo/repro/after_dynamo.py\", line 130, in __call__\n",
      "W0404 11:45:02.289000 54198 site-packages/torch/_dynamo/convert_frame.py:1233]     compiled_gm = compiler_fn(gm, example_inputs)\n",
      "W0404 11:45:02.289000 54198 site-packages/torch/_dynamo/convert_frame.py:1233]   File \"/opt/anaconda3/envs/cs5388-a1/lib/python3.13/site-packages/torch/__init__.py\", line 2340, in __call__\n",
      "W0404 11:45:02.289000 54198 site-packages/torch/_dynamo/convert_frame.py:1233]     return compile_fx(model_, inputs_, config_patches=self.config)\n",
      "W0404 11:45:02.289000 54198 site-packages/torch/_dynamo/convert_frame.py:1233]   File \"/opt/anaconda3/envs/cs5388-a1/lib/python3.13/site-packages/torch/_inductor/compile_fx.py\", line 1863, in compile_fx\n",
      "W0404 11:45:02.289000 54198 site-packages/torch/_dynamo/convert_frame.py:1233]     return aot_autograd(\n",
      "W0404 11:45:02.289000 54198 site-packages/torch/_dynamo/convert_frame.py:1233]            ~~~~~~~~~~~~~\n",
      "W0404 11:45:02.289000 54198 site-packages/torch/_dynamo/convert_frame.py:1233]     ...<6 lines>...\n",
      "W0404 11:45:02.289000 54198 site-packages/torch/_dynamo/convert_frame.py:1233]         cudagraphs=cudagraphs,\n",
      "W0404 11:45:02.289000 54198 site-packages/torch/_dynamo/convert_frame.py:1233]         ~~~~~~~~~~~~~~~~~~~~~~\n",
      "W0404 11:45:02.289000 54198 site-packages/torch/_dynamo/convert_frame.py:1233]     )(model_, example_inputs_)\n",
      "W0404 11:45:02.289000 54198 site-packages/torch/_dynamo/convert_frame.py:1233]     ~^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "W0404 11:45:02.289000 54198 site-packages/torch/_dynamo/convert_frame.py:1233]   File \"/opt/anaconda3/envs/cs5388-a1/lib/python3.13/site-packages/torch/_dynamo/backends/common.py\", line 83, in __call__\n",
      "W0404 11:45:02.289000 54198 site-packages/torch/_dynamo/convert_frame.py:1233]     cg = aot_module_simplified(gm, example_inputs, **self.kwargs)\n",
      "W0404 11:45:02.289000 54198 site-packages/torch/_dynamo/convert_frame.py:1233]   File \"/opt/anaconda3/envs/cs5388-a1/lib/python3.13/site-packages/torch/_functorch/aot_autograd.py\", line 1155, in aot_module_simplified\n",
      "W0404 11:45:02.289000 54198 site-packages/torch/_dynamo/convert_frame.py:1233]     compiled_fn = dispatch_and_compile()\n",
      "W0404 11:45:02.289000 54198 site-packages/torch/_dynamo/convert_frame.py:1233]   File \"/opt/anaconda3/envs/cs5388-a1/lib/python3.13/site-packages/torch/_functorch/aot_autograd.py\", line 1131, in dispatch_and_compile\n",
      "W0404 11:45:02.289000 54198 site-packages/torch/_dynamo/convert_frame.py:1233]     compiled_fn, _ = create_aot_dispatcher_function(\n",
      "W0404 11:45:02.289000 54198 site-packages/torch/_dynamo/convert_frame.py:1233]                      ~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~^\n",
      "W0404 11:45:02.289000 54198 site-packages/torch/_dynamo/convert_frame.py:1233]         functional_call,\n",
      "W0404 11:45:02.289000 54198 site-packages/torch/_dynamo/convert_frame.py:1233]         ^^^^^^^^^^^^^^^^\n",
      "W0404 11:45:02.289000 54198 site-packages/torch/_dynamo/convert_frame.py:1233]     ...<3 lines>...\n",
      "W0404 11:45:02.289000 54198 site-packages/torch/_dynamo/convert_frame.py:1233]         shape_env,\n",
      "W0404 11:45:02.289000 54198 site-packages/torch/_dynamo/convert_frame.py:1233]         ^^^^^^^^^^\n",
      "W0404 11:45:02.289000 54198 site-packages/torch/_dynamo/convert_frame.py:1233]     )\n",
      "W0404 11:45:02.289000 54198 site-packages/torch/_dynamo/convert_frame.py:1233]     ^\n",
      "W0404 11:45:02.289000 54198 site-packages/torch/_dynamo/convert_frame.py:1233]   File \"/opt/anaconda3/envs/cs5388-a1/lib/python3.13/site-packages/torch/_functorch/aot_autograd.py\", line 580, in create_aot_dispatcher_function\n",
      "W0404 11:45:02.289000 54198 site-packages/torch/_dynamo/convert_frame.py:1233]     return _create_aot_dispatcher_function(\n",
      "W0404 11:45:02.289000 54198 site-packages/torch/_dynamo/convert_frame.py:1233]         flat_fn, fake_flat_args, aot_config, fake_mode, shape_env\n",
      "W0404 11:45:02.289000 54198 site-packages/torch/_dynamo/convert_frame.py:1233]     )\n",
      "W0404 11:45:02.289000 54198 site-packages/torch/_dynamo/convert_frame.py:1233]   File \"/opt/anaconda3/envs/cs5388-a1/lib/python3.13/site-packages/torch/_functorch/aot_autograd.py\", line 830, in _create_aot_dispatcher_function\n",
      "W0404 11:45:02.289000 54198 site-packages/torch/_dynamo/convert_frame.py:1233]     compiled_fn, fw_metadata = compiler_fn(\n",
      "W0404 11:45:02.289000 54198 site-packages/torch/_dynamo/convert_frame.py:1233]                                ~~~~~~~~~~~^\n",
      "W0404 11:45:02.289000 54198 site-packages/torch/_dynamo/convert_frame.py:1233]         flat_fn,\n",
      "W0404 11:45:02.289000 54198 site-packages/torch/_dynamo/convert_frame.py:1233]         ^^^^^^^^\n",
      "W0404 11:45:02.289000 54198 site-packages/torch/_dynamo/convert_frame.py:1233]     ...<2 lines>...\n",
      "W0404 11:45:02.289000 54198 site-packages/torch/_dynamo/convert_frame.py:1233]         fw_metadata=fw_metadata,\n",
      "W0404 11:45:02.289000 54198 site-packages/torch/_dynamo/convert_frame.py:1233]         ^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "W0404 11:45:02.289000 54198 site-packages/torch/_dynamo/convert_frame.py:1233]     )\n",
      "W0404 11:45:02.289000 54198 site-packages/torch/_dynamo/convert_frame.py:1233]     ^\n",
      "W0404 11:45:02.289000 54198 site-packages/torch/_dynamo/convert_frame.py:1233]   File \"/opt/anaconda3/envs/cs5388-a1/lib/python3.13/site-packages/torch/_functorch/_aot_autograd/jit_compile_runtime_wrappers.py\", line 678, in aot_dispatch_autograd\n",
      "W0404 11:45:02.289000 54198 site-packages/torch/_dynamo/convert_frame.py:1233]     compiled_fw_func = aot_config.fw_compiler(fw_module, adjusted_flat_args)\n",
      "W0404 11:45:02.289000 54198 site-packages/torch/_dynamo/convert_frame.py:1233]   File \"/opt/anaconda3/envs/cs5388-a1/lib/python3.13/site-packages/torch/_functorch/aot_autograd.py\", line 489, in __call__\n",
      "W0404 11:45:02.289000 54198 site-packages/torch/_dynamo/convert_frame.py:1233]     return self.compiler_fn(gm, example_inputs)\n",
      "W0404 11:45:02.289000 54198 site-packages/torch/_dynamo/convert_frame.py:1233]            ~~~~~~~~~~~~~~~~^^^^^^^^^^^^^^^^^^^^\n",
      "W0404 11:45:02.289000 54198 site-packages/torch/_dynamo/convert_frame.py:1233]   File \"/opt/anaconda3/envs/cs5388-a1/lib/python3.13/site-packages/torch/_inductor/compile_fx.py\", line 1741, in fw_compiler_base\n",
      "W0404 11:45:02.289000 54198 site-packages/torch/_dynamo/convert_frame.py:1233]     return inner_compile(\n",
      "W0404 11:45:02.289000 54198 site-packages/torch/_dynamo/convert_frame.py:1233]         gm,\n",
      "W0404 11:45:02.289000 54198 site-packages/torch/_dynamo/convert_frame.py:1233]     ...<5 lines>...\n",
      "W0404 11:45:02.289000 54198 site-packages/torch/_dynamo/convert_frame.py:1233]         boxed_forward_device_index=forward_device,\n",
      "W0404 11:45:02.289000 54198 site-packages/torch/_dynamo/convert_frame.py:1233]     )\n",
      "W0404 11:45:02.289000 54198 site-packages/torch/_dynamo/convert_frame.py:1233]   File \"/opt/anaconda3/envs/cs5388-a1/lib/python3.13/site-packages/torch/_inductor/compile_fx.py\", line 569, in compile_fx_inner\n",
      "W0404 11:45:02.289000 54198 site-packages/torch/_dynamo/convert_frame.py:1233]     return wrap_compiler_debug(_compile_fx_inner, compiler_name=\"inductor\")(\n",
      "W0404 11:45:02.289000 54198 site-packages/torch/_dynamo/convert_frame.py:1233]            ~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~^\n",
      "W0404 11:45:02.289000 54198 site-packages/torch/_dynamo/convert_frame.py:1233]         gm,\n",
      "W0404 11:45:02.289000 54198 site-packages/torch/_dynamo/convert_frame.py:1233]         ^^^\n",
      "W0404 11:45:02.289000 54198 site-packages/torch/_dynamo/convert_frame.py:1233]         example_inputs,\n",
      "W0404 11:45:02.289000 54198 site-packages/torch/_dynamo/convert_frame.py:1233]         ^^^^^^^^^^^^^^^\n",
      "W0404 11:45:02.289000 54198 site-packages/torch/_dynamo/convert_frame.py:1233]         **kwargs,\n",
      "W0404 11:45:02.289000 54198 site-packages/torch/_dynamo/convert_frame.py:1233]         ^^^^^^^^^\n",
      "W0404 11:45:02.289000 54198 site-packages/torch/_dynamo/convert_frame.py:1233]     )\n",
      "W0404 11:45:02.289000 54198 site-packages/torch/_dynamo/convert_frame.py:1233]     ^\n",
      "W0404 11:45:02.289000 54198 site-packages/torch/_dynamo/convert_frame.py:1233]   File \"/opt/anaconda3/envs/cs5388-a1/lib/python3.13/site-packages/torch/_dynamo/repro/after_aot.py\", line 102, in debug_wrapper\n",
      "W0404 11:45:02.289000 54198 site-packages/torch/_dynamo/convert_frame.py:1233]     inner_compiled_fn = compiler_fn(gm, example_inputs)\n",
      "W0404 11:45:02.289000 54198 site-packages/torch/_dynamo/convert_frame.py:1233]   File \"/opt/anaconda3/envs/cs5388-a1/lib/python3.13/site-packages/torch/_inductor/compile_fx.py\", line 685, in _compile_fx_inner\n",
      "W0404 11:45:02.289000 54198 site-packages/torch/_dynamo/convert_frame.py:1233]     mb_compiled_graph = fx_codegen_and_compile(\n",
      "W0404 11:45:02.289000 54198 site-packages/torch/_dynamo/convert_frame.py:1233]         gm, example_inputs, inputs_to_check, **graph_kwargs\n",
      "W0404 11:45:02.289000 54198 site-packages/torch/_dynamo/convert_frame.py:1233]     )\n",
      "W0404 11:45:02.289000 54198 site-packages/torch/_dynamo/convert_frame.py:1233]   File \"/opt/anaconda3/envs/cs5388-a1/lib/python3.13/site-packages/torch/_inductor/compile_fx.py\", line 1129, in fx_codegen_and_compile\n",
      "W0404 11:45:02.289000 54198 site-packages/torch/_dynamo/convert_frame.py:1233]     return scheme.codegen_and_compile(gm, example_inputs, inputs_to_check, graph_kwargs)\n",
      "W0404 11:45:02.289000 54198 site-packages/torch/_dynamo/convert_frame.py:1233]            ~~~~~~~~~~~~~~~~~~~~~~~~~~^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "W0404 11:45:02.289000 54198 site-packages/torch/_dynamo/convert_frame.py:1233]   File \"/opt/anaconda3/envs/cs5388-a1/lib/python3.13/site-packages/torch/_inductor/compile_fx.py\", line 1044, in codegen_and_compile\n",
      "W0404 11:45:02.289000 54198 site-packages/torch/_dynamo/convert_frame.py:1233]     compiled_fn = graph.compile_to_module().call\n",
      "W0404 11:45:02.289000 54198 site-packages/torch/_dynamo/convert_frame.py:1233]                   ~~~~~~~~~~~~~~~~~~~~~~~^^\n",
      "W0404 11:45:02.289000 54198 site-packages/torch/_dynamo/convert_frame.py:1233]   File \"/opt/anaconda3/envs/cs5388-a1/lib/python3.13/site-packages/torch/_inductor/graph.py\", line 2027, in compile_to_module\n",
      "W0404 11:45:02.289000 54198 site-packages/torch/_dynamo/convert_frame.py:1233]     return self._compile_to_module()\n",
      "W0404 11:45:02.289000 54198 site-packages/torch/_dynamo/convert_frame.py:1233]            ~~~~~~~~~~~~~~~~~~~~~~~^^\n",
      "W0404 11:45:02.289000 54198 site-packages/torch/_dynamo/convert_frame.py:1233]   File \"/opt/anaconda3/envs/cs5388-a1/lib/python3.13/site-packages/torch/_inductor/graph.py\", line 2033, in _compile_to_module\n",
      "W0404 11:45:02.289000 54198 site-packages/torch/_dynamo/convert_frame.py:1233]     self.codegen_with_cpp_wrapper() if self.cpp_wrapper else self.codegen()\n",
      "W0404 11:45:02.289000 54198 site-packages/torch/_dynamo/convert_frame.py:1233]                                                              ~~~~~~~~~~~~^^\n",
      "W0404 11:45:02.289000 54198 site-packages/torch/_dynamo/convert_frame.py:1233]   File \"/opt/anaconda3/envs/cs5388-a1/lib/python3.13/site-packages/torch/_inductor/graph.py\", line 1968, in codegen\n",
      "W0404 11:45:02.289000 54198 site-packages/torch/_dynamo/convert_frame.py:1233]     self.scheduler.codegen()\n",
      "W0404 11:45:02.289000 54198 site-packages/torch/_dynamo/convert_frame.py:1233]     ~~~~~~~~~~~~~~~~~~~~~~^^\n",
      "W0404 11:45:02.289000 54198 site-packages/torch/_dynamo/convert_frame.py:1233]   File \"/opt/anaconda3/envs/cs5388-a1/lib/python3.13/site-packages/torch/_inductor/scheduler.py\", line 3477, in codegen\n",
      "W0404 11:45:02.289000 54198 site-packages/torch/_dynamo/convert_frame.py:1233]     return self._codegen()\n",
      "W0404 11:45:02.289000 54198 site-packages/torch/_dynamo/convert_frame.py:1233]            ~~~~~~~~~~~~~^^\n",
      "W0404 11:45:02.289000 54198 site-packages/torch/_dynamo/convert_frame.py:1233]   File \"/opt/anaconda3/envs/cs5388-a1/lib/python3.13/site-packages/torch/_inductor/scheduler.py\", line 3554, in _codegen\n",
      "W0404 11:45:02.289000 54198 site-packages/torch/_dynamo/convert_frame.py:1233]     self.get_backend(device).codegen_node(node)\n",
      "W0404 11:45:02.289000 54198 site-packages/torch/_dynamo/convert_frame.py:1233]     ~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~^^^^^^\n",
      "W0404 11:45:02.289000 54198 site-packages/torch/_dynamo/convert_frame.py:1233]   File \"/opt/anaconda3/envs/cs5388-a1/lib/python3.13/site-packages/torch/_inductor/codegen/cpp.py\", line 4782, in codegen_node\n",
      "W0404 11:45:02.289000 54198 site-packages/torch/_dynamo/convert_frame.py:1233]     cpp_kernel_proxy.codegen_nodes(nodes)\n",
      "W0404 11:45:02.289000 54198 site-packages/torch/_dynamo/convert_frame.py:1233]     ~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~^^^^^^^\n",
      "W0404 11:45:02.289000 54198 site-packages/torch/_dynamo/convert_frame.py:1233]   File \"/opt/anaconda3/envs/cs5388-a1/lib/python3.13/site-packages/torch/_inductor/codegen/cpp.py\", line 4044, in codegen_nodes\n",
      "W0404 11:45:02.289000 54198 site-packages/torch/_dynamo/convert_frame.py:1233]     self.codegen_functions(fn_list, var_sizes_list)\n",
      "W0404 11:45:02.289000 54198 site-packages/torch/_dynamo/convert_frame.py:1233]     ~~~~~~~~~~~~~~~~~~~~~~^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "W0404 11:45:02.289000 54198 site-packages/torch/_dynamo/convert_frame.py:1233]   File \"/opt/anaconda3/envs/cs5388-a1/lib/python3.13/site-packages/torch/_inductor/codegen/cpp.py\", line 3862, in codegen_functions\n",
      "W0404 11:45:02.289000 54198 site-packages/torch/_dynamo/convert_frame.py:1233]     self.loop_nest = LoopNest.build(scalar_kernel)\n",
      "W0404 11:45:02.289000 54198 site-packages/torch/_dynamo/convert_frame.py:1233]                      ~~~~~~~~~~~~~~^^^^^^^^^^^^^^^\n",
      "W0404 11:45:02.289000 54198 site-packages/torch/_dynamo/convert_frame.py:1233]   File \"/opt/anaconda3/envs/cs5388-a1/lib/python3.13/site-packages/torch/_inductor/codegen/cpp.py\", line 5124, in build\n",
      "W0404 11:45:02.289000 54198 site-packages/torch/_dynamo/convert_frame.py:1233]     loop = LoopLevel(var, size)\n",
      "W0404 11:45:02.289000 54198 site-packages/torch/_dynamo/convert_frame.py:1233]   File \"<string>\", line 13, in __init__\n",
      "W0404 11:45:02.289000 54198 site-packages/torch/_dynamo/convert_frame.py:1233]   File \"/opt/anaconda3/envs/cs5388-a1/lib/python3.13/site-packages/torch/_inductor/codegen/cpp.py\", line 5045, in __post_init__\n",
      "W0404 11:45:02.289000 54198 site-packages/torch/_dynamo/convert_frame.py:1233]     self.simd_nelements: int = picked_vec_isa.nelements() if picked_vec_isa else 0\n",
      "W0404 11:45:02.289000 54198 site-packages/torch/_dynamo/convert_frame.py:1233]                                                              ^^^^^^^^^^^^^^\n",
      "W0404 11:45:02.289000 54198 site-packages/torch/_dynamo/convert_frame.py:1233]   File \"/opt/anaconda3/envs/cs5388-a1/lib/python3.13/site-packages/torch/_inductor/cpu_vec_isa.py\", line 142, in __bool__\n",
      "W0404 11:45:02.289000 54198 site-packages/torch/_dynamo/convert_frame.py:1233]     return self.__bool__impl(config.cpp.vec_isa_ok)\n",
      "W0404 11:45:02.289000 54198 site-packages/torch/_dynamo/convert_frame.py:1233]            ~~~~~~~~~~~~~~~~~^^^^^^^^^^^^^^^^^^^^^^^\n",
      "W0404 11:45:02.289000 54198 site-packages/torch/_dynamo/convert_frame.py:1233]   File \"/opt/anaconda3/envs/cs5388-a1/lib/python3.13/site-packages/torch/_inductor/cpu_vec_isa.py\", line 152, in __bool__impl\n",
      "W0404 11:45:02.289000 54198 site-packages/torch/_dynamo/convert_frame.py:1233]     return self.check_build(VecISA._avx_code)\n",
      "W0404 11:45:02.289000 54198 site-packages/torch/_dynamo/convert_frame.py:1233]            ~~~~~~~~~~~~~~~~^^^^^^^^^^^^^^^^^^\n",
      "W0404 11:45:02.289000 54198 site-packages/torch/_dynamo/convert_frame.py:1233]   File \"/opt/anaconda3/envs/cs5388-a1/lib/python3.13/site-packages/torch/_inductor/cpu_vec_isa.py\", line 102, in check_build\n",
      "W0404 11:45:02.289000 54198 site-packages/torch/_dynamo/convert_frame.py:1233]     extra=_get_isa_dry_compile_fingerprint(self._arch_flags),\n",
      "W0404 11:45:02.289000 54198 site-packages/torch/_dynamo/convert_frame.py:1233]           ~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~^^^^^^^^^^^^^^^^^^\n",
      "W0404 11:45:02.289000 54198 site-packages/torch/_dynamo/convert_frame.py:1233]   File \"/opt/anaconda3/envs/cs5388-a1/lib/python3.13/site-packages/torch/_inductor/cpu_vec_isa.py\", line 28, in _get_isa_dry_compile_fingerprint\n",
      "W0404 11:45:02.289000 54198 site-packages/torch/_dynamo/convert_frame.py:1233]     compiler_info = get_compiler_version_info(get_cpp_compiler())\n",
      "W0404 11:45:02.289000 54198 site-packages/torch/_dynamo/convert_frame.py:1233]                                               ~~~~~~~~~~~~~~~~^^\n",
      "W0404 11:45:02.289000 54198 site-packages/torch/_dynamo/convert_frame.py:1233]   File \"/opt/anaconda3/envs/cs5388-a1/lib/python3.13/site-packages/torch/_inductor/cpp_builder.py\", line 152, in get_cpp_compiler\n",
      "W0404 11:45:02.289000 54198 site-packages/torch/_dynamo/convert_frame.py:1233]     compiler = cpp_compiler_search(search)\n",
      "W0404 11:45:02.289000 54198 site-packages/torch/_dynamo/convert_frame.py:1233]   File \"/opt/anaconda3/envs/cs5388-a1/lib/python3.13/site-packages/torch/_inductor/cpp_builder.py\", line 94, in cpp_compiler_search\n",
      "W0404 11:45:02.289000 54198 site-packages/torch/_dynamo/convert_frame.py:1233]     raise exc.InvalidCxxCompiler\n",
      "W0404 11:45:02.289000 54198 site-packages/torch/_dynamo/convert_frame.py:1233] torch._dynamo.exc.BackendCompilerFailed: backend='inductor' raised:\n",
      "W0404 11:45:02.289000 54198 site-packages/torch/_dynamo/convert_frame.py:1233] InvalidCxxCompiler: No working C++ compiler found in torch._inductor.config.cpp.cxx: (None, 'arm64-apple-darwin20.0.0-clang++')\n",
      "W0404 11:45:02.289000 54198 site-packages/torch/_dynamo/convert_frame.py:1233] \n",
      "W0404 11:45:02.289000 54198 site-packages/torch/_dynamo/convert_frame.py:1233] Set TORCH_LOGS=\"+dynamo\" and TORCHDYNAMO_VERBOSE=1 for more information\n",
      "W0404 11:45:02.289000 54198 site-packages/torch/_dynamo/convert_frame.py:1233] \n",
      "W0404 11:45:02.441000 54198 site-packages/torch/_dynamo/convert_frame.py:1233] WON'T CONVERT forward /var/folders/lg/6yppdn9s1750q5k7b8v6mfz4dwvtts/T/ipykernel_54198/250187466.py line 14 \n",
      "W0404 11:45:02.441000 54198 site-packages/torch/_dynamo/convert_frame.py:1233] due to: \n",
      "W0404 11:45:02.441000 54198 site-packages/torch/_dynamo/convert_frame.py:1233] Traceback (most recent call last):\n",
      "W0404 11:45:02.441000 54198 site-packages/torch/_dynamo/convert_frame.py:1233]   File \"/opt/anaconda3/envs/cs5388-a1/lib/python3.13/site-packages/torch/_dynamo/convert_frame.py\", line 1164, in __call__\n",
      "W0404 11:45:02.441000 54198 site-packages/torch/_dynamo/convert_frame.py:1233]     result = self._inner_convert(\n",
      "W0404 11:45:02.441000 54198 site-packages/torch/_dynamo/convert_frame.py:1233]         frame, cache_entry, hooks, frame_state, skip=skip + 1\n",
      "W0404 11:45:02.441000 54198 site-packages/torch/_dynamo/convert_frame.py:1233]     )\n",
      "W0404 11:45:02.441000 54198 site-packages/torch/_dynamo/convert_frame.py:1233]   File \"/opt/anaconda3/envs/cs5388-a1/lib/python3.13/site-packages/torch/_dynamo/convert_frame.py\", line 547, in __call__\n",
      "W0404 11:45:02.441000 54198 site-packages/torch/_dynamo/convert_frame.py:1233]     return _compile(\n",
      "W0404 11:45:02.441000 54198 site-packages/torch/_dynamo/convert_frame.py:1233]         frame.f_code,\n",
      "W0404 11:45:02.441000 54198 site-packages/torch/_dynamo/convert_frame.py:1233]     ...<14 lines>...\n",
      "W0404 11:45:02.441000 54198 site-packages/torch/_dynamo/convert_frame.py:1233]         skip=skip + 1,\n",
      "W0404 11:45:02.441000 54198 site-packages/torch/_dynamo/convert_frame.py:1233]     )\n",
      "W0404 11:45:02.441000 54198 site-packages/torch/_dynamo/convert_frame.py:1233]   File \"/opt/anaconda3/envs/cs5388-a1/lib/python3.13/site-packages/torch/_dynamo/convert_frame.py\", line 986, in _compile\n",
      "W0404 11:45:02.441000 54198 site-packages/torch/_dynamo/convert_frame.py:1233]     guarded_code = compile_inner(code, one_graph, hooks, transform)\n",
      "W0404 11:45:02.441000 54198 site-packages/torch/_dynamo/convert_frame.py:1233]   File \"/opt/anaconda3/envs/cs5388-a1/lib/python3.13/site-packages/torch/_dynamo/convert_frame.py\", line 715, in compile_inner\n",
      "W0404 11:45:02.441000 54198 site-packages/torch/_dynamo/convert_frame.py:1233]     return _compile_inner(code, one_graph, hooks, transform)\n",
      "W0404 11:45:02.441000 54198 site-packages/torch/_dynamo/convert_frame.py:1233]   File \"/opt/anaconda3/envs/cs5388-a1/lib/python3.13/site-packages/torch/_utils_internal.py\", line 95, in wrapper_function\n",
      "W0404 11:45:02.441000 54198 site-packages/torch/_dynamo/convert_frame.py:1233]     return function(*args, **kwargs)\n",
      "W0404 11:45:02.441000 54198 site-packages/torch/_dynamo/convert_frame.py:1233]   File \"/opt/anaconda3/envs/cs5388-a1/lib/python3.13/site-packages/torch/_dynamo/convert_frame.py\", line 750, in _compile_inner\n",
      "W0404 11:45:02.441000 54198 site-packages/torch/_dynamo/convert_frame.py:1233]     out_code = transform_code_object(code, transform)\n",
      "W0404 11:45:02.441000 54198 site-packages/torch/_dynamo/convert_frame.py:1233]   File \"/opt/anaconda3/envs/cs5388-a1/lib/python3.13/site-packages/torch/_dynamo/bytecode_transformation.py\", line 1361, in transform_code_object\n",
      "W0404 11:45:02.441000 54198 site-packages/torch/_dynamo/convert_frame.py:1233]     transformations(instructions, code_options)\n",
      "W0404 11:45:02.441000 54198 site-packages/torch/_dynamo/convert_frame.py:1233]     ~~~~~~~~~~~~~~~^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "W0404 11:45:02.441000 54198 site-packages/torch/_dynamo/convert_frame.py:1233]   File \"/opt/anaconda3/envs/cs5388-a1/lib/python3.13/site-packages/torch/_dynamo/convert_frame.py\", line 231, in _fn\n",
      "W0404 11:45:02.441000 54198 site-packages/torch/_dynamo/convert_frame.py:1233]     return fn(*args, **kwargs)\n",
      "W0404 11:45:02.441000 54198 site-packages/torch/_dynamo/convert_frame.py:1233]   File \"/opt/anaconda3/envs/cs5388-a1/lib/python3.13/site-packages/torch/_dynamo/convert_frame.py\", line 662, in transform\n",
      "W0404 11:45:02.441000 54198 site-packages/torch/_dynamo/convert_frame.py:1233]     tracer.run()\n",
      "W0404 11:45:02.441000 54198 site-packages/torch/_dynamo/convert_frame.py:1233]     ~~~~~~~~~~^^\n",
      "W0404 11:45:02.441000 54198 site-packages/torch/_dynamo/convert_frame.py:1233]   File \"/opt/anaconda3/envs/cs5388-a1/lib/python3.13/site-packages/torch/_dynamo/symbolic_convert.py\", line 2868, in run\n",
      "W0404 11:45:02.441000 54198 site-packages/torch/_dynamo/convert_frame.py:1233]     super().run()\n",
      "W0404 11:45:02.441000 54198 site-packages/torch/_dynamo/convert_frame.py:1233]     ~~~~~~~~~~~^^\n",
      "W0404 11:45:02.441000 54198 site-packages/torch/_dynamo/convert_frame.py:1233]   File \"/opt/anaconda3/envs/cs5388-a1/lib/python3.13/site-packages/torch/_dynamo/symbolic_convert.py\", line 1052, in run\n",
      "W0404 11:45:02.441000 54198 site-packages/torch/_dynamo/convert_frame.py:1233]     while self.step():\n",
      "W0404 11:45:02.441000 54198 site-packages/torch/_dynamo/convert_frame.py:1233]           ~~~~~~~~~^^\n",
      "W0404 11:45:02.441000 54198 site-packages/torch/_dynamo/convert_frame.py:1233]   File \"/opt/anaconda3/envs/cs5388-a1/lib/python3.13/site-packages/torch/_dynamo/symbolic_convert.py\", line 962, in step\n",
      "W0404 11:45:02.441000 54198 site-packages/torch/_dynamo/convert_frame.py:1233]     self.dispatch_table[inst.opcode](self, inst)\n",
      "W0404 11:45:02.441000 54198 site-packages/torch/_dynamo/convert_frame.py:1233]     ~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~^^^^^^^^^^^^\n",
      "W0404 11:45:02.441000 54198 site-packages/torch/_dynamo/convert_frame.py:1233]   File \"/opt/anaconda3/envs/cs5388-a1/lib/python3.13/site-packages/torch/_dynamo/symbolic_convert.py\", line 3048, in RETURN_VALUE\n",
      "W0404 11:45:02.441000 54198 site-packages/torch/_dynamo/convert_frame.py:1233]     self._return(inst)\n",
      "W0404 11:45:02.441000 54198 site-packages/torch/_dynamo/convert_frame.py:1233]     ~~~~~~~~~~~~^^^^^^\n",
      "W0404 11:45:02.441000 54198 site-packages/torch/_dynamo/convert_frame.py:1233]   File \"/opt/anaconda3/envs/cs5388-a1/lib/python3.13/site-packages/torch/_dynamo/symbolic_convert.py\", line 3033, in _return\n",
      "W0404 11:45:02.441000 54198 site-packages/torch/_dynamo/convert_frame.py:1233]     self.output.compile_subgraph(\n",
      "W0404 11:45:02.441000 54198 site-packages/torch/_dynamo/convert_frame.py:1233]     ~~~~~~~~~~~~~~~~~~~~~~~~~~~~^\n",
      "W0404 11:45:02.441000 54198 site-packages/torch/_dynamo/convert_frame.py:1233]         self,\n",
      "W0404 11:45:02.441000 54198 site-packages/torch/_dynamo/convert_frame.py:1233]         ^^^^^\n",
      "W0404 11:45:02.441000 54198 site-packages/torch/_dynamo/convert_frame.py:1233]     ...<2 lines>...\n",
      "W0404 11:45:02.441000 54198 site-packages/torch/_dynamo/convert_frame.py:1233]         ),\n",
      "W0404 11:45:02.441000 54198 site-packages/torch/_dynamo/convert_frame.py:1233]         ^^\n",
      "W0404 11:45:02.441000 54198 site-packages/torch/_dynamo/convert_frame.py:1233]     )\n",
      "W0404 11:45:02.441000 54198 site-packages/torch/_dynamo/convert_frame.py:1233]     ^\n",
      "W0404 11:45:02.441000 54198 site-packages/torch/_dynamo/convert_frame.py:1233]   File \"/opt/anaconda3/envs/cs5388-a1/lib/python3.13/site-packages/torch/_dynamo/output_graph.py\", line 1101, in compile_subgraph\n",
      "W0404 11:45:02.441000 54198 site-packages/torch/_dynamo/convert_frame.py:1233]     self.compile_and_call_fx_graph(\n",
      "W0404 11:45:02.441000 54198 site-packages/torch/_dynamo/convert_frame.py:1233]     ~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~^\n",
      "W0404 11:45:02.441000 54198 site-packages/torch/_dynamo/convert_frame.py:1233]         tx, list(reversed(stack_values)), root, output_replacements\n",
      "W0404 11:45:02.441000 54198 site-packages/torch/_dynamo/convert_frame.py:1233]         ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "W0404 11:45:02.441000 54198 site-packages/torch/_dynamo/convert_frame.py:1233]     )\n",
      "W0404 11:45:02.441000 54198 site-packages/torch/_dynamo/convert_frame.py:1233]     ^\n",
      "W0404 11:45:02.441000 54198 site-packages/torch/_dynamo/convert_frame.py:1233]   File \"/opt/anaconda3/envs/cs5388-a1/lib/python3.13/site-packages/torch/_dynamo/output_graph.py\", line 1382, in compile_and_call_fx_graph\n",
      "W0404 11:45:02.441000 54198 site-packages/torch/_dynamo/convert_frame.py:1233]     compiled_fn = self.call_user_compiler(gm)\n",
      "W0404 11:45:02.441000 54198 site-packages/torch/_dynamo/convert_frame.py:1233]   File \"/opt/anaconda3/envs/cs5388-a1/lib/python3.13/site-packages/torch/_dynamo/output_graph.py\", line 1432, in call_user_compiler\n",
      "W0404 11:45:02.441000 54198 site-packages/torch/_dynamo/convert_frame.py:1233]     return self._call_user_compiler(gm)\n",
      "W0404 11:45:02.441000 54198 site-packages/torch/_dynamo/convert_frame.py:1233]            ~~~~~~~~~~~~~~~~~~~~~~~~^^^^\n",
      "W0404 11:45:02.441000 54198 site-packages/torch/_dynamo/convert_frame.py:1233]   File \"/opt/anaconda3/envs/cs5388-a1/lib/python3.13/site-packages/torch/_dynamo/output_graph.py\", line 1483, in _call_user_compiler\n",
      "W0404 11:45:02.441000 54198 site-packages/torch/_dynamo/convert_frame.py:1233]     raise BackendCompilerFailed(self.compiler_fn, e).with_traceback(\n",
      "W0404 11:45:02.441000 54198 site-packages/torch/_dynamo/convert_frame.py:1233]         e.__traceback__\n",
      "W0404 11:45:02.441000 54198 site-packages/torch/_dynamo/convert_frame.py:1233]     ) from None\n",
      "W0404 11:45:02.441000 54198 site-packages/torch/_dynamo/convert_frame.py:1233]   File \"/opt/anaconda3/envs/cs5388-a1/lib/python3.13/site-packages/torch/_dynamo/output_graph.py\", line 1462, in _call_user_compiler\n",
      "W0404 11:45:02.441000 54198 site-packages/torch/_dynamo/convert_frame.py:1233]     compiled_fn = compiler_fn(gm, self.example_inputs())\n",
      "W0404 11:45:02.441000 54198 site-packages/torch/_dynamo/convert_frame.py:1233]   File \"/opt/anaconda3/envs/cs5388-a1/lib/python3.13/site-packages/torch/_dynamo/repro/after_dynamo.py\", line 130, in __call__\n",
      "W0404 11:45:02.441000 54198 site-packages/torch/_dynamo/convert_frame.py:1233]     compiled_gm = compiler_fn(gm, example_inputs)\n",
      "W0404 11:45:02.441000 54198 site-packages/torch/_dynamo/convert_frame.py:1233]   File \"/opt/anaconda3/envs/cs5388-a1/lib/python3.13/site-packages/torch/__init__.py\", line 2340, in __call__\n",
      "W0404 11:45:02.441000 54198 site-packages/torch/_dynamo/convert_frame.py:1233]     return compile_fx(model_, inputs_, config_patches=self.config)\n",
      "W0404 11:45:02.441000 54198 site-packages/torch/_dynamo/convert_frame.py:1233]   File \"/opt/anaconda3/envs/cs5388-a1/lib/python3.13/site-packages/torch/_inductor/compile_fx.py\", line 1863, in compile_fx\n",
      "W0404 11:45:02.441000 54198 site-packages/torch/_dynamo/convert_frame.py:1233]     return aot_autograd(\n",
      "W0404 11:45:02.441000 54198 site-packages/torch/_dynamo/convert_frame.py:1233]            ~~~~~~~~~~~~~\n",
      "W0404 11:45:02.441000 54198 site-packages/torch/_dynamo/convert_frame.py:1233]     ...<6 lines>...\n",
      "W0404 11:45:02.441000 54198 site-packages/torch/_dynamo/convert_frame.py:1233]         cudagraphs=cudagraphs,\n",
      "W0404 11:45:02.441000 54198 site-packages/torch/_dynamo/convert_frame.py:1233]         ~~~~~~~~~~~~~~~~~~~~~~\n",
      "W0404 11:45:02.441000 54198 site-packages/torch/_dynamo/convert_frame.py:1233]     )(model_, example_inputs_)\n",
      "W0404 11:45:02.441000 54198 site-packages/torch/_dynamo/convert_frame.py:1233]     ~^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "W0404 11:45:02.441000 54198 site-packages/torch/_dynamo/convert_frame.py:1233]   File \"/opt/anaconda3/envs/cs5388-a1/lib/python3.13/site-packages/torch/_dynamo/backends/common.py\", line 83, in __call__\n",
      "W0404 11:45:02.441000 54198 site-packages/torch/_dynamo/convert_frame.py:1233]     cg = aot_module_simplified(gm, example_inputs, **self.kwargs)\n",
      "W0404 11:45:02.441000 54198 site-packages/torch/_dynamo/convert_frame.py:1233]   File \"/opt/anaconda3/envs/cs5388-a1/lib/python3.13/site-packages/torch/_functorch/aot_autograd.py\", line 1155, in aot_module_simplified\n",
      "W0404 11:45:02.441000 54198 site-packages/torch/_dynamo/convert_frame.py:1233]     compiled_fn = dispatch_and_compile()\n",
      "W0404 11:45:02.441000 54198 site-packages/torch/_dynamo/convert_frame.py:1233]   File \"/opt/anaconda3/envs/cs5388-a1/lib/python3.13/site-packages/torch/_functorch/aot_autograd.py\", line 1131, in dispatch_and_compile\n",
      "W0404 11:45:02.441000 54198 site-packages/torch/_dynamo/convert_frame.py:1233]     compiled_fn, _ = create_aot_dispatcher_function(\n",
      "W0404 11:45:02.441000 54198 site-packages/torch/_dynamo/convert_frame.py:1233]                      ~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~^\n",
      "W0404 11:45:02.441000 54198 site-packages/torch/_dynamo/convert_frame.py:1233]         functional_call,\n",
      "W0404 11:45:02.441000 54198 site-packages/torch/_dynamo/convert_frame.py:1233]         ^^^^^^^^^^^^^^^^\n",
      "W0404 11:45:02.441000 54198 site-packages/torch/_dynamo/convert_frame.py:1233]     ...<3 lines>...\n",
      "W0404 11:45:02.441000 54198 site-packages/torch/_dynamo/convert_frame.py:1233]         shape_env,\n",
      "W0404 11:45:02.441000 54198 site-packages/torch/_dynamo/convert_frame.py:1233]         ^^^^^^^^^^\n",
      "W0404 11:45:02.441000 54198 site-packages/torch/_dynamo/convert_frame.py:1233]     )\n",
      "W0404 11:45:02.441000 54198 site-packages/torch/_dynamo/convert_frame.py:1233]     ^\n",
      "W0404 11:45:02.441000 54198 site-packages/torch/_dynamo/convert_frame.py:1233]   File \"/opt/anaconda3/envs/cs5388-a1/lib/python3.13/site-packages/torch/_functorch/aot_autograd.py\", line 580, in create_aot_dispatcher_function\n",
      "W0404 11:45:02.441000 54198 site-packages/torch/_dynamo/convert_frame.py:1233]     return _create_aot_dispatcher_function(\n",
      "W0404 11:45:02.441000 54198 site-packages/torch/_dynamo/convert_frame.py:1233]         flat_fn, fake_flat_args, aot_config, fake_mode, shape_env\n",
      "W0404 11:45:02.441000 54198 site-packages/torch/_dynamo/convert_frame.py:1233]     )\n",
      "W0404 11:45:02.441000 54198 site-packages/torch/_dynamo/convert_frame.py:1233]   File \"/opt/anaconda3/envs/cs5388-a1/lib/python3.13/site-packages/torch/_functorch/aot_autograd.py\", line 830, in _create_aot_dispatcher_function\n",
      "W0404 11:45:02.441000 54198 site-packages/torch/_dynamo/convert_frame.py:1233]     compiled_fn, fw_metadata = compiler_fn(\n",
      "W0404 11:45:02.441000 54198 site-packages/torch/_dynamo/convert_frame.py:1233]                                ~~~~~~~~~~~^\n",
      "W0404 11:45:02.441000 54198 site-packages/torch/_dynamo/convert_frame.py:1233]         flat_fn,\n",
      "W0404 11:45:02.441000 54198 site-packages/torch/_dynamo/convert_frame.py:1233]         ^^^^^^^^\n",
      "W0404 11:45:02.441000 54198 site-packages/torch/_dynamo/convert_frame.py:1233]     ...<2 lines>...\n",
      "W0404 11:45:02.441000 54198 site-packages/torch/_dynamo/convert_frame.py:1233]         fw_metadata=fw_metadata,\n",
      "W0404 11:45:02.441000 54198 site-packages/torch/_dynamo/convert_frame.py:1233]         ^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "W0404 11:45:02.441000 54198 site-packages/torch/_dynamo/convert_frame.py:1233]     )\n",
      "W0404 11:45:02.441000 54198 site-packages/torch/_dynamo/convert_frame.py:1233]     ^\n",
      "W0404 11:45:02.441000 54198 site-packages/torch/_dynamo/convert_frame.py:1233]   File \"/opt/anaconda3/envs/cs5388-a1/lib/python3.13/site-packages/torch/_functorch/_aot_autograd/jit_compile_runtime_wrappers.py\", line 678, in aot_dispatch_autograd\n",
      "W0404 11:45:02.441000 54198 site-packages/torch/_dynamo/convert_frame.py:1233]     compiled_fw_func = aot_config.fw_compiler(fw_module, adjusted_flat_args)\n",
      "W0404 11:45:02.441000 54198 site-packages/torch/_dynamo/convert_frame.py:1233]   File \"/opt/anaconda3/envs/cs5388-a1/lib/python3.13/site-packages/torch/_functorch/aot_autograd.py\", line 489, in __call__\n",
      "W0404 11:45:02.441000 54198 site-packages/torch/_dynamo/convert_frame.py:1233]     return self.compiler_fn(gm, example_inputs)\n",
      "W0404 11:45:02.441000 54198 site-packages/torch/_dynamo/convert_frame.py:1233]            ~~~~~~~~~~~~~~~~^^^^^^^^^^^^^^^^^^^^\n",
      "W0404 11:45:02.441000 54198 site-packages/torch/_dynamo/convert_frame.py:1233]   File \"/opt/anaconda3/envs/cs5388-a1/lib/python3.13/site-packages/torch/_inductor/compile_fx.py\", line 1741, in fw_compiler_base\n",
      "W0404 11:45:02.441000 54198 site-packages/torch/_dynamo/convert_frame.py:1233]     return inner_compile(\n",
      "W0404 11:45:02.441000 54198 site-packages/torch/_dynamo/convert_frame.py:1233]         gm,\n",
      "W0404 11:45:02.441000 54198 site-packages/torch/_dynamo/convert_frame.py:1233]     ...<5 lines>...\n",
      "W0404 11:45:02.441000 54198 site-packages/torch/_dynamo/convert_frame.py:1233]         boxed_forward_device_index=forward_device,\n",
      "W0404 11:45:02.441000 54198 site-packages/torch/_dynamo/convert_frame.py:1233]     )\n",
      "W0404 11:45:02.441000 54198 site-packages/torch/_dynamo/convert_frame.py:1233]   File \"/opt/anaconda3/envs/cs5388-a1/lib/python3.13/site-packages/torch/_inductor/compile_fx.py\", line 569, in compile_fx_inner\n",
      "W0404 11:45:02.441000 54198 site-packages/torch/_dynamo/convert_frame.py:1233]     return wrap_compiler_debug(_compile_fx_inner, compiler_name=\"inductor\")(\n",
      "W0404 11:45:02.441000 54198 site-packages/torch/_dynamo/convert_frame.py:1233]            ~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~^\n",
      "W0404 11:45:02.441000 54198 site-packages/torch/_dynamo/convert_frame.py:1233]         gm,\n",
      "W0404 11:45:02.441000 54198 site-packages/torch/_dynamo/convert_frame.py:1233]         ^^^\n",
      "W0404 11:45:02.441000 54198 site-packages/torch/_dynamo/convert_frame.py:1233]         example_inputs,\n",
      "W0404 11:45:02.441000 54198 site-packages/torch/_dynamo/convert_frame.py:1233]         ^^^^^^^^^^^^^^^\n",
      "W0404 11:45:02.441000 54198 site-packages/torch/_dynamo/convert_frame.py:1233]         **kwargs,\n",
      "W0404 11:45:02.441000 54198 site-packages/torch/_dynamo/convert_frame.py:1233]         ^^^^^^^^^\n",
      "W0404 11:45:02.441000 54198 site-packages/torch/_dynamo/convert_frame.py:1233]     )\n",
      "W0404 11:45:02.441000 54198 site-packages/torch/_dynamo/convert_frame.py:1233]     ^\n",
      "W0404 11:45:02.441000 54198 site-packages/torch/_dynamo/convert_frame.py:1233]   File \"/opt/anaconda3/envs/cs5388-a1/lib/python3.13/site-packages/torch/_dynamo/repro/after_aot.py\", line 102, in debug_wrapper\n",
      "W0404 11:45:02.441000 54198 site-packages/torch/_dynamo/convert_frame.py:1233]     inner_compiled_fn = compiler_fn(gm, example_inputs)\n",
      "W0404 11:45:02.441000 54198 site-packages/torch/_dynamo/convert_frame.py:1233]   File \"/opt/anaconda3/envs/cs5388-a1/lib/python3.13/site-packages/torch/_inductor/compile_fx.py\", line 685, in _compile_fx_inner\n",
      "W0404 11:45:02.441000 54198 site-packages/torch/_dynamo/convert_frame.py:1233]     mb_compiled_graph = fx_codegen_and_compile(\n",
      "W0404 11:45:02.441000 54198 site-packages/torch/_dynamo/convert_frame.py:1233]         gm, example_inputs, inputs_to_check, **graph_kwargs\n",
      "W0404 11:45:02.441000 54198 site-packages/torch/_dynamo/convert_frame.py:1233]     )\n",
      "W0404 11:45:02.441000 54198 site-packages/torch/_dynamo/convert_frame.py:1233]   File \"/opt/anaconda3/envs/cs5388-a1/lib/python3.13/site-packages/torch/_inductor/compile_fx.py\", line 1129, in fx_codegen_and_compile\n",
      "W0404 11:45:02.441000 54198 site-packages/torch/_dynamo/convert_frame.py:1233]     return scheme.codegen_and_compile(gm, example_inputs, inputs_to_check, graph_kwargs)\n",
      "W0404 11:45:02.441000 54198 site-packages/torch/_dynamo/convert_frame.py:1233]            ~~~~~~~~~~~~~~~~~~~~~~~~~~^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "W0404 11:45:02.441000 54198 site-packages/torch/_dynamo/convert_frame.py:1233]   File \"/opt/anaconda3/envs/cs5388-a1/lib/python3.13/site-packages/torch/_inductor/compile_fx.py\", line 1044, in codegen_and_compile\n",
      "W0404 11:45:02.441000 54198 site-packages/torch/_dynamo/convert_frame.py:1233]     compiled_fn = graph.compile_to_module().call\n",
      "W0404 11:45:02.441000 54198 site-packages/torch/_dynamo/convert_frame.py:1233]                   ~~~~~~~~~~~~~~~~~~~~~~~^^\n",
      "W0404 11:45:02.441000 54198 site-packages/torch/_dynamo/convert_frame.py:1233]   File \"/opt/anaconda3/envs/cs5388-a1/lib/python3.13/site-packages/torch/_inductor/graph.py\", line 2027, in compile_to_module\n",
      "W0404 11:45:02.441000 54198 site-packages/torch/_dynamo/convert_frame.py:1233]     return self._compile_to_module()\n",
      "W0404 11:45:02.441000 54198 site-packages/torch/_dynamo/convert_frame.py:1233]            ~~~~~~~~~~~~~~~~~~~~~~~^^\n",
      "W0404 11:45:02.441000 54198 site-packages/torch/_dynamo/convert_frame.py:1233]   File \"/opt/anaconda3/envs/cs5388-a1/lib/python3.13/site-packages/torch/_inductor/graph.py\", line 2033, in _compile_to_module\n",
      "W0404 11:45:02.441000 54198 site-packages/torch/_dynamo/convert_frame.py:1233]     self.codegen_with_cpp_wrapper() if self.cpp_wrapper else self.codegen()\n",
      "W0404 11:45:02.441000 54198 site-packages/torch/_dynamo/convert_frame.py:1233]                                                              ~~~~~~~~~~~~^^\n",
      "W0404 11:45:02.441000 54198 site-packages/torch/_dynamo/convert_frame.py:1233]   File \"/opt/anaconda3/envs/cs5388-a1/lib/python3.13/site-packages/torch/_inductor/graph.py\", line 1968, in codegen\n",
      "W0404 11:45:02.441000 54198 site-packages/torch/_dynamo/convert_frame.py:1233]     self.scheduler.codegen()\n",
      "W0404 11:45:02.441000 54198 site-packages/torch/_dynamo/convert_frame.py:1233]     ~~~~~~~~~~~~~~~~~~~~~~^^\n",
      "W0404 11:45:02.441000 54198 site-packages/torch/_dynamo/convert_frame.py:1233]   File \"/opt/anaconda3/envs/cs5388-a1/lib/python3.13/site-packages/torch/_inductor/scheduler.py\", line 3477, in codegen\n",
      "W0404 11:45:02.441000 54198 site-packages/torch/_dynamo/convert_frame.py:1233]     return self._codegen()\n",
      "W0404 11:45:02.441000 54198 site-packages/torch/_dynamo/convert_frame.py:1233]            ~~~~~~~~~~~~~^^\n",
      "W0404 11:45:02.441000 54198 site-packages/torch/_dynamo/convert_frame.py:1233]   File \"/opt/anaconda3/envs/cs5388-a1/lib/python3.13/site-packages/torch/_inductor/scheduler.py\", line 3554, in _codegen\n",
      "W0404 11:45:02.441000 54198 site-packages/torch/_dynamo/convert_frame.py:1233]     self.get_backend(device).codegen_node(node)\n",
      "W0404 11:45:02.441000 54198 site-packages/torch/_dynamo/convert_frame.py:1233]     ~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~^^^^^^\n",
      "W0404 11:45:02.441000 54198 site-packages/torch/_dynamo/convert_frame.py:1233]   File \"/opt/anaconda3/envs/cs5388-a1/lib/python3.13/site-packages/torch/_inductor/codegen/cpp.py\", line 4782, in codegen_node\n",
      "W0404 11:45:02.441000 54198 site-packages/torch/_dynamo/convert_frame.py:1233]     cpp_kernel_proxy.codegen_nodes(nodes)\n",
      "W0404 11:45:02.441000 54198 site-packages/torch/_dynamo/convert_frame.py:1233]     ~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~^^^^^^^\n",
      "W0404 11:45:02.441000 54198 site-packages/torch/_dynamo/convert_frame.py:1233]   File \"/opt/anaconda3/envs/cs5388-a1/lib/python3.13/site-packages/torch/_inductor/codegen/cpp.py\", line 4044, in codegen_nodes\n",
      "W0404 11:45:02.441000 54198 site-packages/torch/_dynamo/convert_frame.py:1233]     self.codegen_functions(fn_list, var_sizes_list)\n",
      "W0404 11:45:02.441000 54198 site-packages/torch/_dynamo/convert_frame.py:1233]     ~~~~~~~~~~~~~~~~~~~~~~^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "W0404 11:45:02.441000 54198 site-packages/torch/_dynamo/convert_frame.py:1233]   File \"/opt/anaconda3/envs/cs5388-a1/lib/python3.13/site-packages/torch/_inductor/codegen/cpp.py\", line 3864, in codegen_functions\n",
      "W0404 11:45:02.441000 54198 site-packages/torch/_dynamo/convert_frame.py:1233]     if not self.picked_vec_isa or not self.itervars:\n",
      "W0404 11:45:02.441000 54198 site-packages/torch/_dynamo/convert_frame.py:1233]            ^^^^^^^^^^^^^^^^^^^\n",
      "W0404 11:45:02.441000 54198 site-packages/torch/_dynamo/convert_frame.py:1233]   File \"/opt/anaconda3/envs/cs5388-a1/lib/python3.13/site-packages/torch/_inductor/cpu_vec_isa.py\", line 142, in __bool__\n",
      "W0404 11:45:02.441000 54198 site-packages/torch/_dynamo/convert_frame.py:1233]     return self.__bool__impl(config.cpp.vec_isa_ok)\n",
      "W0404 11:45:02.441000 54198 site-packages/torch/_dynamo/convert_frame.py:1233]            ~~~~~~~~~~~~~~~~~^^^^^^^^^^^^^^^^^^^^^^^\n",
      "W0404 11:45:02.441000 54198 site-packages/torch/_dynamo/convert_frame.py:1233]   File \"/opt/anaconda3/envs/cs5388-a1/lib/python3.13/site-packages/torch/_inductor/cpu_vec_isa.py\", line 152, in __bool__impl\n",
      "W0404 11:45:02.441000 54198 site-packages/torch/_dynamo/convert_frame.py:1233]     return self.check_build(VecISA._avx_code)\n",
      "W0404 11:45:02.441000 54198 site-packages/torch/_dynamo/convert_frame.py:1233]            ~~~~~~~~~~~~~~~~^^^^^^^^^^^^^^^^^^\n",
      "W0404 11:45:02.441000 54198 site-packages/torch/_dynamo/convert_frame.py:1233]   File \"/opt/anaconda3/envs/cs5388-a1/lib/python3.13/site-packages/torch/_inductor/cpu_vec_isa.py\", line 102, in check_build\n",
      "W0404 11:45:02.441000 54198 site-packages/torch/_dynamo/convert_frame.py:1233]     extra=_get_isa_dry_compile_fingerprint(self._arch_flags),\n",
      "W0404 11:45:02.441000 54198 site-packages/torch/_dynamo/convert_frame.py:1233]           ~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~^^^^^^^^^^^^^^^^^^\n",
      "W0404 11:45:02.441000 54198 site-packages/torch/_dynamo/convert_frame.py:1233]   File \"/opt/anaconda3/envs/cs5388-a1/lib/python3.13/site-packages/torch/_inductor/cpu_vec_isa.py\", line 28, in _get_isa_dry_compile_fingerprint\n",
      "W0404 11:45:02.441000 54198 site-packages/torch/_dynamo/convert_frame.py:1233]     compiler_info = get_compiler_version_info(get_cpp_compiler())\n",
      "W0404 11:45:02.441000 54198 site-packages/torch/_dynamo/convert_frame.py:1233]                                               ~~~~~~~~~~~~~~~~^^\n",
      "W0404 11:45:02.441000 54198 site-packages/torch/_dynamo/convert_frame.py:1233]   File \"/opt/anaconda3/envs/cs5388-a1/lib/python3.13/site-packages/torch/_inductor/cpp_builder.py\", line 152, in get_cpp_compiler\n",
      "W0404 11:45:02.441000 54198 site-packages/torch/_dynamo/convert_frame.py:1233]     compiler = cpp_compiler_search(search)\n",
      "W0404 11:45:02.441000 54198 site-packages/torch/_dynamo/convert_frame.py:1233]   File \"/opt/anaconda3/envs/cs5388-a1/lib/python3.13/site-packages/torch/_inductor/cpp_builder.py\", line 94, in cpp_compiler_search\n",
      "W0404 11:45:02.441000 54198 site-packages/torch/_dynamo/convert_frame.py:1233]     raise exc.InvalidCxxCompiler\n",
      "W0404 11:45:02.441000 54198 site-packages/torch/_dynamo/convert_frame.py:1233] torch._dynamo.exc.BackendCompilerFailed: backend='inductor' raised:\n",
      "W0404 11:45:02.441000 54198 site-packages/torch/_dynamo/convert_frame.py:1233] InvalidCxxCompiler: No working C++ compiler found in torch._inductor.config.cpp.cxx: (None, 'arm64-apple-darwin20.0.0-clang++')\n",
      "W0404 11:45:02.441000 54198 site-packages/torch/_dynamo/convert_frame.py:1233] \n",
      "W0404 11:45:02.441000 54198 site-packages/torch/_dynamo/convert_frame.py:1233] Set TORCH_LOGS=\"+dynamo\" and TORCHDYNAMO_VERBOSE=1 for more information\n",
      "W0404 11:45:02.441000 54198 site-packages/torch/_dynamo/convert_frame.py:1233] \n",
      "W0404 11:45:02.441000 54198 site-packages/torch/_dynamo/convert_frame.py:1233] Traceback (most recent call last):\n",
      "W0404 11:45:02.441000 54198 site-packages/torch/_dynamo/convert_frame.py:1233]   File \"/opt/anaconda3/envs/cs5388-a1/lib/python3.13/site-packages/torch/_dynamo/convert_frame.py\", line 1164, in __call__\n",
      "W0404 11:45:02.441000 54198 site-packages/torch/_dynamo/convert_frame.py:1233]     result = self._inner_convert(\n",
      "W0404 11:45:02.441000 54198 site-packages/torch/_dynamo/convert_frame.py:1233]         frame, cache_entry, hooks, frame_state, skip=skip + 1\n",
      "W0404 11:45:02.441000 54198 site-packages/torch/_dynamo/convert_frame.py:1233]     )\n",
      "W0404 11:45:02.441000 54198 site-packages/torch/_dynamo/convert_frame.py:1233]   File \"/opt/anaconda3/envs/cs5388-a1/lib/python3.13/site-packages/torch/_dynamo/convert_frame.py\", line 547, in __call__\n",
      "W0404 11:45:02.441000 54198 site-packages/torch/_dynamo/convert_frame.py:1233]     return _compile(\n",
      "W0404 11:45:02.441000 54198 site-packages/torch/_dynamo/convert_frame.py:1233]         frame.f_code,\n",
      "W0404 11:45:02.441000 54198 site-packages/torch/_dynamo/convert_frame.py:1233]     ...<14 lines>...\n",
      "W0404 11:45:02.441000 54198 site-packages/torch/_dynamo/convert_frame.py:1233]         skip=skip + 1,\n",
      "W0404 11:45:02.441000 54198 site-packages/torch/_dynamo/convert_frame.py:1233]     )\n",
      "W0404 11:45:02.441000 54198 site-packages/torch/_dynamo/convert_frame.py:1233]   File \"/opt/anaconda3/envs/cs5388-a1/lib/python3.13/site-packages/torch/_dynamo/convert_frame.py\", line 986, in _compile\n",
      "W0404 11:45:02.441000 54198 site-packages/torch/_dynamo/convert_frame.py:1233]     guarded_code = compile_inner(code, one_graph, hooks, transform)\n",
      "W0404 11:45:02.441000 54198 site-packages/torch/_dynamo/convert_frame.py:1233]   File \"/opt/anaconda3/envs/cs5388-a1/lib/python3.13/site-packages/torch/_dynamo/convert_frame.py\", line 715, in compile_inner\n",
      "W0404 11:45:02.441000 54198 site-packages/torch/_dynamo/convert_frame.py:1233]     return _compile_inner(code, one_graph, hooks, transform)\n",
      "W0404 11:45:02.441000 54198 site-packages/torch/_dynamo/convert_frame.py:1233]   File \"/opt/anaconda3/envs/cs5388-a1/lib/python3.13/site-packages/torch/_utils_internal.py\", line 95, in wrapper_function\n",
      "W0404 11:45:02.441000 54198 site-packages/torch/_dynamo/convert_frame.py:1233]     return function(*args, **kwargs)\n",
      "W0404 11:45:02.441000 54198 site-packages/torch/_dynamo/convert_frame.py:1233]   File \"/opt/anaconda3/envs/cs5388-a1/lib/python3.13/site-packages/torch/_dynamo/convert_frame.py\", line 750, in _compile_inner\n",
      "W0404 11:45:02.441000 54198 site-packages/torch/_dynamo/convert_frame.py:1233]     out_code = transform_code_object(code, transform)\n",
      "W0404 11:45:02.441000 54198 site-packages/torch/_dynamo/convert_frame.py:1233]   File \"/opt/anaconda3/envs/cs5388-a1/lib/python3.13/site-packages/torch/_dynamo/bytecode_transformation.py\", line 1361, in transform_code_object\n",
      "W0404 11:45:02.441000 54198 site-packages/torch/_dynamo/convert_frame.py:1233]     transformations(instructions, code_options)\n",
      "W0404 11:45:02.441000 54198 site-packages/torch/_dynamo/convert_frame.py:1233]     ~~~~~~~~~~~~~~~^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "W0404 11:45:02.441000 54198 site-packages/torch/_dynamo/convert_frame.py:1233]   File \"/opt/anaconda3/envs/cs5388-a1/lib/python3.13/site-packages/torch/_dynamo/convert_frame.py\", line 231, in _fn\n",
      "W0404 11:45:02.441000 54198 site-packages/torch/_dynamo/convert_frame.py:1233]     return fn(*args, **kwargs)\n",
      "W0404 11:45:02.441000 54198 site-packages/torch/_dynamo/convert_frame.py:1233]   File \"/opt/anaconda3/envs/cs5388-a1/lib/python3.13/site-packages/torch/_dynamo/convert_frame.py\", line 662, in transform\n",
      "W0404 11:45:02.441000 54198 site-packages/torch/_dynamo/convert_frame.py:1233]     tracer.run()\n",
      "W0404 11:45:02.441000 54198 site-packages/torch/_dynamo/convert_frame.py:1233]     ~~~~~~~~~~^^\n",
      "W0404 11:45:02.441000 54198 site-packages/torch/_dynamo/convert_frame.py:1233]   File \"/opt/anaconda3/envs/cs5388-a1/lib/python3.13/site-packages/torch/_dynamo/symbolic_convert.py\", line 2868, in run\n",
      "W0404 11:45:02.441000 54198 site-packages/torch/_dynamo/convert_frame.py:1233]     super().run()\n",
      "W0404 11:45:02.441000 54198 site-packages/torch/_dynamo/convert_frame.py:1233]     ~~~~~~~~~~~^^\n",
      "W0404 11:45:02.441000 54198 site-packages/torch/_dynamo/convert_frame.py:1233]   File \"/opt/anaconda3/envs/cs5388-a1/lib/python3.13/site-packages/torch/_dynamo/symbolic_convert.py\", line 1052, in run\n",
      "W0404 11:45:02.441000 54198 site-packages/torch/_dynamo/convert_frame.py:1233]     while self.step():\n",
      "W0404 11:45:02.441000 54198 site-packages/torch/_dynamo/convert_frame.py:1233]           ~~~~~~~~~^^\n",
      "W0404 11:45:02.441000 54198 site-packages/torch/_dynamo/convert_frame.py:1233]   File \"/opt/anaconda3/envs/cs5388-a1/lib/python3.13/site-packages/torch/_dynamo/symbolic_convert.py\", line 962, in step\n",
      "W0404 11:45:02.441000 54198 site-packages/torch/_dynamo/convert_frame.py:1233]     self.dispatch_table[inst.opcode](self, inst)\n",
      "W0404 11:45:02.441000 54198 site-packages/torch/_dynamo/convert_frame.py:1233]     ~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~^^^^^^^^^^^^\n",
      "W0404 11:45:02.441000 54198 site-packages/torch/_dynamo/convert_frame.py:1233]   File \"/opt/anaconda3/envs/cs5388-a1/lib/python3.13/site-packages/torch/_dynamo/symbolic_convert.py\", line 3048, in RETURN_VALUE\n",
      "W0404 11:45:02.441000 54198 site-packages/torch/_dynamo/convert_frame.py:1233]     self._return(inst)\n",
      "W0404 11:45:02.441000 54198 site-packages/torch/_dynamo/convert_frame.py:1233]     ~~~~~~~~~~~~^^^^^^\n",
      "W0404 11:45:02.441000 54198 site-packages/torch/_dynamo/convert_frame.py:1233]   File \"/opt/anaconda3/envs/cs5388-a1/lib/python3.13/site-packages/torch/_dynamo/symbolic_convert.py\", line 3033, in _return\n",
      "W0404 11:45:02.441000 54198 site-packages/torch/_dynamo/convert_frame.py:1233]     self.output.compile_subgraph(\n",
      "W0404 11:45:02.441000 54198 site-packages/torch/_dynamo/convert_frame.py:1233]     ~~~~~~~~~~~~~~~~~~~~~~~~~~~~^\n",
      "W0404 11:45:02.441000 54198 site-packages/torch/_dynamo/convert_frame.py:1233]         self,\n",
      "W0404 11:45:02.441000 54198 site-packages/torch/_dynamo/convert_frame.py:1233]         ^^^^^\n",
      "W0404 11:45:02.441000 54198 site-packages/torch/_dynamo/convert_frame.py:1233]     ...<2 lines>...\n",
      "W0404 11:45:02.441000 54198 site-packages/torch/_dynamo/convert_frame.py:1233]         ),\n",
      "W0404 11:45:02.441000 54198 site-packages/torch/_dynamo/convert_frame.py:1233]         ^^\n",
      "W0404 11:45:02.441000 54198 site-packages/torch/_dynamo/convert_frame.py:1233]     )\n",
      "W0404 11:45:02.441000 54198 site-packages/torch/_dynamo/convert_frame.py:1233]     ^\n",
      "W0404 11:45:02.441000 54198 site-packages/torch/_dynamo/convert_frame.py:1233]   File \"/opt/anaconda3/envs/cs5388-a1/lib/python3.13/site-packages/torch/_dynamo/output_graph.py\", line 1101, in compile_subgraph\n",
      "W0404 11:45:02.441000 54198 site-packages/torch/_dynamo/convert_frame.py:1233]     self.compile_and_call_fx_graph(\n",
      "W0404 11:45:02.441000 54198 site-packages/torch/_dynamo/convert_frame.py:1233]     ~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~^\n",
      "W0404 11:45:02.441000 54198 site-packages/torch/_dynamo/convert_frame.py:1233]         tx, list(reversed(stack_values)), root, output_replacements\n",
      "W0404 11:45:02.441000 54198 site-packages/torch/_dynamo/convert_frame.py:1233]         ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "W0404 11:45:02.441000 54198 site-packages/torch/_dynamo/convert_frame.py:1233]     )\n",
      "W0404 11:45:02.441000 54198 site-packages/torch/_dynamo/convert_frame.py:1233]     ^\n",
      "W0404 11:45:02.441000 54198 site-packages/torch/_dynamo/convert_frame.py:1233]   File \"/opt/anaconda3/envs/cs5388-a1/lib/python3.13/site-packages/torch/_dynamo/output_graph.py\", line 1382, in compile_and_call_fx_graph\n",
      "W0404 11:45:02.441000 54198 site-packages/torch/_dynamo/convert_frame.py:1233]     compiled_fn = self.call_user_compiler(gm)\n",
      "W0404 11:45:02.441000 54198 site-packages/torch/_dynamo/convert_frame.py:1233]   File \"/opt/anaconda3/envs/cs5388-a1/lib/python3.13/site-packages/torch/_dynamo/output_graph.py\", line 1432, in call_user_compiler\n",
      "W0404 11:45:02.441000 54198 site-packages/torch/_dynamo/convert_frame.py:1233]     return self._call_user_compiler(gm)\n",
      "W0404 11:45:02.441000 54198 site-packages/torch/_dynamo/convert_frame.py:1233]            ~~~~~~~~~~~~~~~~~~~~~~~~^^^^\n",
      "W0404 11:45:02.441000 54198 site-packages/torch/_dynamo/convert_frame.py:1233]   File \"/opt/anaconda3/envs/cs5388-a1/lib/python3.13/site-packages/torch/_dynamo/output_graph.py\", line 1483, in _call_user_compiler\n",
      "W0404 11:45:02.441000 54198 site-packages/torch/_dynamo/convert_frame.py:1233]     raise BackendCompilerFailed(self.compiler_fn, e).with_traceback(\n",
      "W0404 11:45:02.441000 54198 site-packages/torch/_dynamo/convert_frame.py:1233]         e.__traceback__\n",
      "W0404 11:45:02.441000 54198 site-packages/torch/_dynamo/convert_frame.py:1233]     ) from None\n",
      "W0404 11:45:02.441000 54198 site-packages/torch/_dynamo/convert_frame.py:1233]   File \"/opt/anaconda3/envs/cs5388-a1/lib/python3.13/site-packages/torch/_dynamo/output_graph.py\", line 1462, in _call_user_compiler\n",
      "W0404 11:45:02.441000 54198 site-packages/torch/_dynamo/convert_frame.py:1233]     compiled_fn = compiler_fn(gm, self.example_inputs())\n",
      "W0404 11:45:02.441000 54198 site-packages/torch/_dynamo/convert_frame.py:1233]   File \"/opt/anaconda3/envs/cs5388-a1/lib/python3.13/site-packages/torch/_dynamo/repro/after_dynamo.py\", line 130, in __call__\n",
      "W0404 11:45:02.441000 54198 site-packages/torch/_dynamo/convert_frame.py:1233]     compiled_gm = compiler_fn(gm, example_inputs)\n",
      "W0404 11:45:02.441000 54198 site-packages/torch/_dynamo/convert_frame.py:1233]   File \"/opt/anaconda3/envs/cs5388-a1/lib/python3.13/site-packages/torch/__init__.py\", line 2340, in __call__\n",
      "W0404 11:45:02.441000 54198 site-packages/torch/_dynamo/convert_frame.py:1233]     return compile_fx(model_, inputs_, config_patches=self.config)\n",
      "W0404 11:45:02.441000 54198 site-packages/torch/_dynamo/convert_frame.py:1233]   File \"/opt/anaconda3/envs/cs5388-a1/lib/python3.13/site-packages/torch/_inductor/compile_fx.py\", line 1863, in compile_fx\n",
      "W0404 11:45:02.441000 54198 site-packages/torch/_dynamo/convert_frame.py:1233]     return aot_autograd(\n",
      "W0404 11:45:02.441000 54198 site-packages/torch/_dynamo/convert_frame.py:1233]            ~~~~~~~~~~~~~\n",
      "W0404 11:45:02.441000 54198 site-packages/torch/_dynamo/convert_frame.py:1233]     ...<6 lines>...\n",
      "W0404 11:45:02.441000 54198 site-packages/torch/_dynamo/convert_frame.py:1233]         cudagraphs=cudagraphs,\n",
      "W0404 11:45:02.441000 54198 site-packages/torch/_dynamo/convert_frame.py:1233]         ~~~~~~~~~~~~~~~~~~~~~~\n",
      "W0404 11:45:02.441000 54198 site-packages/torch/_dynamo/convert_frame.py:1233]     )(model_, example_inputs_)\n",
      "W0404 11:45:02.441000 54198 site-packages/torch/_dynamo/convert_frame.py:1233]     ~^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "W0404 11:45:02.441000 54198 site-packages/torch/_dynamo/convert_frame.py:1233]   File \"/opt/anaconda3/envs/cs5388-a1/lib/python3.13/site-packages/torch/_dynamo/backends/common.py\", line 83, in __call__\n",
      "W0404 11:45:02.441000 54198 site-packages/torch/_dynamo/convert_frame.py:1233]     cg = aot_module_simplified(gm, example_inputs, **self.kwargs)\n",
      "W0404 11:45:02.441000 54198 site-packages/torch/_dynamo/convert_frame.py:1233]   File \"/opt/anaconda3/envs/cs5388-a1/lib/python3.13/site-packages/torch/_functorch/aot_autograd.py\", line 1155, in aot_module_simplified\n",
      "W0404 11:45:02.441000 54198 site-packages/torch/_dynamo/convert_frame.py:1233]     compiled_fn = dispatch_and_compile()\n",
      "W0404 11:45:02.441000 54198 site-packages/torch/_dynamo/convert_frame.py:1233]   File \"/opt/anaconda3/envs/cs5388-a1/lib/python3.13/site-packages/torch/_functorch/aot_autograd.py\", line 1131, in dispatch_and_compile\n",
      "W0404 11:45:02.441000 54198 site-packages/torch/_dynamo/convert_frame.py:1233]     compiled_fn, _ = create_aot_dispatcher_function(\n",
      "W0404 11:45:02.441000 54198 site-packages/torch/_dynamo/convert_frame.py:1233]                      ~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~^\n",
      "W0404 11:45:02.441000 54198 site-packages/torch/_dynamo/convert_frame.py:1233]         functional_call,\n",
      "W0404 11:45:02.441000 54198 site-packages/torch/_dynamo/convert_frame.py:1233]         ^^^^^^^^^^^^^^^^\n",
      "W0404 11:45:02.441000 54198 site-packages/torch/_dynamo/convert_frame.py:1233]     ...<3 lines>...\n",
      "W0404 11:45:02.441000 54198 site-packages/torch/_dynamo/convert_frame.py:1233]         shape_env,\n",
      "W0404 11:45:02.441000 54198 site-packages/torch/_dynamo/convert_frame.py:1233]         ^^^^^^^^^^\n",
      "W0404 11:45:02.441000 54198 site-packages/torch/_dynamo/convert_frame.py:1233]     )\n",
      "W0404 11:45:02.441000 54198 site-packages/torch/_dynamo/convert_frame.py:1233]     ^\n",
      "W0404 11:45:02.441000 54198 site-packages/torch/_dynamo/convert_frame.py:1233]   File \"/opt/anaconda3/envs/cs5388-a1/lib/python3.13/site-packages/torch/_functorch/aot_autograd.py\", line 580, in create_aot_dispatcher_function\n",
      "W0404 11:45:02.441000 54198 site-packages/torch/_dynamo/convert_frame.py:1233]     return _create_aot_dispatcher_function(\n",
      "W0404 11:45:02.441000 54198 site-packages/torch/_dynamo/convert_frame.py:1233]         flat_fn, fake_flat_args, aot_config, fake_mode, shape_env\n",
      "W0404 11:45:02.441000 54198 site-packages/torch/_dynamo/convert_frame.py:1233]     )\n",
      "W0404 11:45:02.441000 54198 site-packages/torch/_dynamo/convert_frame.py:1233]   File \"/opt/anaconda3/envs/cs5388-a1/lib/python3.13/site-packages/torch/_functorch/aot_autograd.py\", line 830, in _create_aot_dispatcher_function\n",
      "W0404 11:45:02.441000 54198 site-packages/torch/_dynamo/convert_frame.py:1233]     compiled_fn, fw_metadata = compiler_fn(\n",
      "W0404 11:45:02.441000 54198 site-packages/torch/_dynamo/convert_frame.py:1233]                                ~~~~~~~~~~~^\n",
      "W0404 11:45:02.441000 54198 site-packages/torch/_dynamo/convert_frame.py:1233]         flat_fn,\n",
      "W0404 11:45:02.441000 54198 site-packages/torch/_dynamo/convert_frame.py:1233]         ^^^^^^^^\n",
      "W0404 11:45:02.441000 54198 site-packages/torch/_dynamo/convert_frame.py:1233]     ...<2 lines>...\n",
      "W0404 11:45:02.441000 54198 site-packages/torch/_dynamo/convert_frame.py:1233]         fw_metadata=fw_metadata,\n",
      "W0404 11:45:02.441000 54198 site-packages/torch/_dynamo/convert_frame.py:1233]         ^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "W0404 11:45:02.441000 54198 site-packages/torch/_dynamo/convert_frame.py:1233]     )\n",
      "W0404 11:45:02.441000 54198 site-packages/torch/_dynamo/convert_frame.py:1233]     ^\n",
      "W0404 11:45:02.441000 54198 site-packages/torch/_dynamo/convert_frame.py:1233]   File \"/opt/anaconda3/envs/cs5388-a1/lib/python3.13/site-packages/torch/_functorch/_aot_autograd/jit_compile_runtime_wrappers.py\", line 678, in aot_dispatch_autograd\n",
      "W0404 11:45:02.441000 54198 site-packages/torch/_dynamo/convert_frame.py:1233]     compiled_fw_func = aot_config.fw_compiler(fw_module, adjusted_flat_args)\n",
      "W0404 11:45:02.441000 54198 site-packages/torch/_dynamo/convert_frame.py:1233]   File \"/opt/anaconda3/envs/cs5388-a1/lib/python3.13/site-packages/torch/_functorch/aot_autograd.py\", line 489, in __call__\n",
      "W0404 11:45:02.441000 54198 site-packages/torch/_dynamo/convert_frame.py:1233]     return self.compiler_fn(gm, example_inputs)\n",
      "W0404 11:45:02.441000 54198 site-packages/torch/_dynamo/convert_frame.py:1233]            ~~~~~~~~~~~~~~~~^^^^^^^^^^^^^^^^^^^^\n",
      "W0404 11:45:02.441000 54198 site-packages/torch/_dynamo/convert_frame.py:1233]   File \"/opt/anaconda3/envs/cs5388-a1/lib/python3.13/site-packages/torch/_inductor/compile_fx.py\", line 1741, in fw_compiler_base\n",
      "W0404 11:45:02.441000 54198 site-packages/torch/_dynamo/convert_frame.py:1233]     return inner_compile(\n",
      "W0404 11:45:02.441000 54198 site-packages/torch/_dynamo/convert_frame.py:1233]         gm,\n",
      "W0404 11:45:02.441000 54198 site-packages/torch/_dynamo/convert_frame.py:1233]     ...<5 lines>...\n",
      "W0404 11:45:02.441000 54198 site-packages/torch/_dynamo/convert_frame.py:1233]         boxed_forward_device_index=forward_device,\n",
      "W0404 11:45:02.441000 54198 site-packages/torch/_dynamo/convert_frame.py:1233]     )\n",
      "W0404 11:45:02.441000 54198 site-packages/torch/_dynamo/convert_frame.py:1233]   File \"/opt/anaconda3/envs/cs5388-a1/lib/python3.13/site-packages/torch/_inductor/compile_fx.py\", line 569, in compile_fx_inner\n",
      "W0404 11:45:02.441000 54198 site-packages/torch/_dynamo/convert_frame.py:1233]     return wrap_compiler_debug(_compile_fx_inner, compiler_name=\"inductor\")(\n",
      "W0404 11:45:02.441000 54198 site-packages/torch/_dynamo/convert_frame.py:1233]            ~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~^\n",
      "W0404 11:45:02.441000 54198 site-packages/torch/_dynamo/convert_frame.py:1233]         gm,\n",
      "W0404 11:45:02.441000 54198 site-packages/torch/_dynamo/convert_frame.py:1233]         ^^^\n",
      "W0404 11:45:02.441000 54198 site-packages/torch/_dynamo/convert_frame.py:1233]         example_inputs,\n",
      "W0404 11:45:02.441000 54198 site-packages/torch/_dynamo/convert_frame.py:1233]         ^^^^^^^^^^^^^^^\n",
      "W0404 11:45:02.441000 54198 site-packages/torch/_dynamo/convert_frame.py:1233]         **kwargs,\n",
      "W0404 11:45:02.441000 54198 site-packages/torch/_dynamo/convert_frame.py:1233]         ^^^^^^^^^\n",
      "W0404 11:45:02.441000 54198 site-packages/torch/_dynamo/convert_frame.py:1233]     )\n",
      "W0404 11:45:02.441000 54198 site-packages/torch/_dynamo/convert_frame.py:1233]     ^\n",
      "W0404 11:45:02.441000 54198 site-packages/torch/_dynamo/convert_frame.py:1233]   File \"/opt/anaconda3/envs/cs5388-a1/lib/python3.13/site-packages/torch/_dynamo/repro/after_aot.py\", line 102, in debug_wrapper\n",
      "W0404 11:45:02.441000 54198 site-packages/torch/_dynamo/convert_frame.py:1233]     inner_compiled_fn = compiler_fn(gm, example_inputs)\n",
      "W0404 11:45:02.441000 54198 site-packages/torch/_dynamo/convert_frame.py:1233]   File \"/opt/anaconda3/envs/cs5388-a1/lib/python3.13/site-packages/torch/_inductor/compile_fx.py\", line 685, in _compile_fx_inner\n",
      "W0404 11:45:02.441000 54198 site-packages/torch/_dynamo/convert_frame.py:1233]     mb_compiled_graph = fx_codegen_and_compile(\n",
      "W0404 11:45:02.441000 54198 site-packages/torch/_dynamo/convert_frame.py:1233]         gm, example_inputs, inputs_to_check, **graph_kwargs\n",
      "W0404 11:45:02.441000 54198 site-packages/torch/_dynamo/convert_frame.py:1233]     )\n",
      "W0404 11:45:02.441000 54198 site-packages/torch/_dynamo/convert_frame.py:1233]   File \"/opt/anaconda3/envs/cs5388-a1/lib/python3.13/site-packages/torch/_inductor/compile_fx.py\", line 1129, in fx_codegen_and_compile\n",
      "W0404 11:45:02.441000 54198 site-packages/torch/_dynamo/convert_frame.py:1233]     return scheme.codegen_and_compile(gm, example_inputs, inputs_to_check, graph_kwargs)\n",
      "W0404 11:45:02.441000 54198 site-packages/torch/_dynamo/convert_frame.py:1233]            ~~~~~~~~~~~~~~~~~~~~~~~~~~^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "W0404 11:45:02.441000 54198 site-packages/torch/_dynamo/convert_frame.py:1233]   File \"/opt/anaconda3/envs/cs5388-a1/lib/python3.13/site-packages/torch/_inductor/compile_fx.py\", line 1044, in codegen_and_compile\n",
      "W0404 11:45:02.441000 54198 site-packages/torch/_dynamo/convert_frame.py:1233]     compiled_fn = graph.compile_to_module().call\n",
      "W0404 11:45:02.441000 54198 site-packages/torch/_dynamo/convert_frame.py:1233]                   ~~~~~~~~~~~~~~~~~~~~~~~^^\n",
      "W0404 11:45:02.441000 54198 site-packages/torch/_dynamo/convert_frame.py:1233]   File \"/opt/anaconda3/envs/cs5388-a1/lib/python3.13/site-packages/torch/_inductor/graph.py\", line 2027, in compile_to_module\n",
      "W0404 11:45:02.441000 54198 site-packages/torch/_dynamo/convert_frame.py:1233]     return self._compile_to_module()\n",
      "W0404 11:45:02.441000 54198 site-packages/torch/_dynamo/convert_frame.py:1233]            ~~~~~~~~~~~~~~~~~~~~~~~^^\n",
      "W0404 11:45:02.441000 54198 site-packages/torch/_dynamo/convert_frame.py:1233]   File \"/opt/anaconda3/envs/cs5388-a1/lib/python3.13/site-packages/torch/_inductor/graph.py\", line 2033, in _compile_to_module\n",
      "W0404 11:45:02.441000 54198 site-packages/torch/_dynamo/convert_frame.py:1233]     self.codegen_with_cpp_wrapper() if self.cpp_wrapper else self.codegen()\n",
      "W0404 11:45:02.441000 54198 site-packages/torch/_dynamo/convert_frame.py:1233]                                                              ~~~~~~~~~~~~^^\n",
      "W0404 11:45:02.441000 54198 site-packages/torch/_dynamo/convert_frame.py:1233]   File \"/opt/anaconda3/envs/cs5388-a1/lib/python3.13/site-packages/torch/_inductor/graph.py\", line 1968, in codegen\n",
      "W0404 11:45:02.441000 54198 site-packages/torch/_dynamo/convert_frame.py:1233]     self.scheduler.codegen()\n",
      "W0404 11:45:02.441000 54198 site-packages/torch/_dynamo/convert_frame.py:1233]     ~~~~~~~~~~~~~~~~~~~~~~^^\n",
      "W0404 11:45:02.441000 54198 site-packages/torch/_dynamo/convert_frame.py:1233]   File \"/opt/anaconda3/envs/cs5388-a1/lib/python3.13/site-packages/torch/_inductor/scheduler.py\", line 3477, in codegen\n",
      "W0404 11:45:02.441000 54198 site-packages/torch/_dynamo/convert_frame.py:1233]     return self._codegen()\n",
      "W0404 11:45:02.441000 54198 site-packages/torch/_dynamo/convert_frame.py:1233]            ~~~~~~~~~~~~~^^\n",
      "W0404 11:45:02.441000 54198 site-packages/torch/_dynamo/convert_frame.py:1233]   File \"/opt/anaconda3/envs/cs5388-a1/lib/python3.13/site-packages/torch/_inductor/scheduler.py\", line 3554, in _codegen\n",
      "W0404 11:45:02.441000 54198 site-packages/torch/_dynamo/convert_frame.py:1233]     self.get_backend(device).codegen_node(node)\n",
      "W0404 11:45:02.441000 54198 site-packages/torch/_dynamo/convert_frame.py:1233]     ~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~^^^^^^\n",
      "W0404 11:45:02.441000 54198 site-packages/torch/_dynamo/convert_frame.py:1233]   File \"/opt/anaconda3/envs/cs5388-a1/lib/python3.13/site-packages/torch/_inductor/codegen/cpp.py\", line 4782, in codegen_node\n",
      "W0404 11:45:02.441000 54198 site-packages/torch/_dynamo/convert_frame.py:1233]     cpp_kernel_proxy.codegen_nodes(nodes)\n",
      "W0404 11:45:02.441000 54198 site-packages/torch/_dynamo/convert_frame.py:1233]     ~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~^^^^^^^\n",
      "W0404 11:45:02.441000 54198 site-packages/torch/_dynamo/convert_frame.py:1233]   File \"/opt/anaconda3/envs/cs5388-a1/lib/python3.13/site-packages/torch/_inductor/codegen/cpp.py\", line 4044, in codegen_nodes\n",
      "W0404 11:45:02.441000 54198 site-packages/torch/_dynamo/convert_frame.py:1233]     self.codegen_functions(fn_list, var_sizes_list)\n",
      "W0404 11:45:02.441000 54198 site-packages/torch/_dynamo/convert_frame.py:1233]     ~~~~~~~~~~~~~~~~~~~~~~^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "W0404 11:45:02.441000 54198 site-packages/torch/_dynamo/convert_frame.py:1233]   File \"/opt/anaconda3/envs/cs5388-a1/lib/python3.13/site-packages/torch/_inductor/codegen/cpp.py\", line 3864, in codegen_functions\n",
      "W0404 11:45:02.441000 54198 site-packages/torch/_dynamo/convert_frame.py:1233]     if not self.picked_vec_isa or not self.itervars:\n",
      "W0404 11:45:02.441000 54198 site-packages/torch/_dynamo/convert_frame.py:1233]            ^^^^^^^^^^^^^^^^^^^\n",
      "W0404 11:45:02.441000 54198 site-packages/torch/_dynamo/convert_frame.py:1233]   File \"/opt/anaconda3/envs/cs5388-a1/lib/python3.13/site-packages/torch/_inductor/cpu_vec_isa.py\", line 142, in __bool__\n",
      "W0404 11:45:02.441000 54198 site-packages/torch/_dynamo/convert_frame.py:1233]     return self.__bool__impl(config.cpp.vec_isa_ok)\n",
      "W0404 11:45:02.441000 54198 site-packages/torch/_dynamo/convert_frame.py:1233]            ~~~~~~~~~~~~~~~~~^^^^^^^^^^^^^^^^^^^^^^^\n",
      "W0404 11:45:02.441000 54198 site-packages/torch/_dynamo/convert_frame.py:1233]   File \"/opt/anaconda3/envs/cs5388-a1/lib/python3.13/site-packages/torch/_inductor/cpu_vec_isa.py\", line 152, in __bool__impl\n",
      "W0404 11:45:02.441000 54198 site-packages/torch/_dynamo/convert_frame.py:1233]     return self.check_build(VecISA._avx_code)\n",
      "W0404 11:45:02.441000 54198 site-packages/torch/_dynamo/convert_frame.py:1233]            ~~~~~~~~~~~~~~~~^^^^^^^^^^^^^^^^^^\n",
      "W0404 11:45:02.441000 54198 site-packages/torch/_dynamo/convert_frame.py:1233]   File \"/opt/anaconda3/envs/cs5388-a1/lib/python3.13/site-packages/torch/_inductor/cpu_vec_isa.py\", line 102, in check_build\n",
      "W0404 11:45:02.441000 54198 site-packages/torch/_dynamo/convert_frame.py:1233]     extra=_get_isa_dry_compile_fingerprint(self._arch_flags),\n",
      "W0404 11:45:02.441000 54198 site-packages/torch/_dynamo/convert_frame.py:1233]           ~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~^^^^^^^^^^^^^^^^^^\n",
      "W0404 11:45:02.441000 54198 site-packages/torch/_dynamo/convert_frame.py:1233]   File \"/opt/anaconda3/envs/cs5388-a1/lib/python3.13/site-packages/torch/_inductor/cpu_vec_isa.py\", line 28, in _get_isa_dry_compile_fingerprint\n",
      "W0404 11:45:02.441000 54198 site-packages/torch/_dynamo/convert_frame.py:1233]     compiler_info = get_compiler_version_info(get_cpp_compiler())\n",
      "W0404 11:45:02.441000 54198 site-packages/torch/_dynamo/convert_frame.py:1233]                                               ~~~~~~~~~~~~~~~~^^\n",
      "W0404 11:45:02.441000 54198 site-packages/torch/_dynamo/convert_frame.py:1233]   File \"/opt/anaconda3/envs/cs5388-a1/lib/python3.13/site-packages/torch/_inductor/cpp_builder.py\", line 152, in get_cpp_compiler\n",
      "W0404 11:45:02.441000 54198 site-packages/torch/_dynamo/convert_frame.py:1233]     compiler = cpp_compiler_search(search)\n",
      "W0404 11:45:02.441000 54198 site-packages/torch/_dynamo/convert_frame.py:1233]   File \"/opt/anaconda3/envs/cs5388-a1/lib/python3.13/site-packages/torch/_inductor/cpp_builder.py\", line 94, in cpp_compiler_search\n",
      "W0404 11:45:02.441000 54198 site-packages/torch/_dynamo/convert_frame.py:1233]     raise exc.InvalidCxxCompiler\n",
      "W0404 11:45:02.441000 54198 site-packages/torch/_dynamo/convert_frame.py:1233] torch._dynamo.exc.BackendCompilerFailed: backend='inductor' raised:\n",
      "W0404 11:45:02.441000 54198 site-packages/torch/_dynamo/convert_frame.py:1233] InvalidCxxCompiler: No working C++ compiler found in torch._inductor.config.cpp.cxx: (None, 'arm64-apple-darwin20.0.0-clang++')\n",
      "W0404 11:45:02.441000 54198 site-packages/torch/_dynamo/convert_frame.py:1233] \n",
      "W0404 11:45:02.441000 54198 site-packages/torch/_dynamo/convert_frame.py:1233] Set TORCH_LOGS=\"+dynamo\" and TORCHDYNAMO_VERBOSE=1 for more information\n",
      "W0404 11:45:02.441000 54198 site-packages/torch/_dynamo/convert_frame.py:1233] \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train - Loss: 648.5659 Accuracy: 0.7548\n",
      "Valid - Loss: 65.9750 Accuracy: 0.9010\n",
      "Epoch: 1\n",
      "Train - Loss: 112.6115 Accuracy: 0.9583\n",
      "Valid - Loss: 33.0639 Accuracy: 0.9490\n",
      "Epoch: 2\n",
      "Train - Loss: 56.4515 Accuracy: 0.9790\n",
      "Valid - Loss: 23.5174 Accuracy: 0.9587\n",
      "Epoch: 3\n",
      "Train - Loss: 44.2285 Accuracy: 0.9837\n",
      "Valid - Loss: 77.9578 Accuracy: 0.8841\n",
      "Epoch: 4\n",
      "Train - Loss: 36.4000 Accuracy: 0.9873\n",
      "Valid - Loss: 27.6017 Accuracy: 0.9668\n",
      "Epoch: 5\n",
      "Train - Loss: 31.6429 Accuracy: 0.9882\n",
      "Valid - Loss: 21.9469 Accuracy: 0.9670\n",
      "Epoch: 6\n",
      "Train - Loss: 24.8619 Accuracy: 0.9907\n",
      "Valid - Loss: 14.4635 Accuracy: 0.9868\n",
      "Epoch: 7\n",
      "Train - Loss: 26.9627 Accuracy: 0.9899\n",
      "Valid - Loss: 42.2746 Accuracy: 0.9625\n",
      "Epoch: 8\n",
      "Train - Loss: 22.2130 Accuracy: 0.9911\n",
      "Valid - Loss: 50.2151 Accuracy: 0.9347\n",
      "Epoch: 9\n",
      "Train - Loss: 21.4932 Accuracy: 0.9924\n",
      "Valid - Loss: 20.0456 Accuracy: 0.9753\n",
      "Epoch: 10\n",
      "Train - Loss: 15.6553 Accuracy: 0.9942\n",
      "Valid - Loss: 32.2727 Accuracy: 0.9651\n",
      "Epoch: 11\n",
      "Train - Loss: 15.6636 Accuracy: 0.9940\n",
      "Valid - Loss: 17.0842 Accuracy: 0.9815\n",
      "Epoch: 12\n",
      "Train - Loss: 21.1278 Accuracy: 0.9922\n",
      "Valid - Loss: 27.8042 Accuracy: 0.9731\n",
      "Epoch: 13\n",
      "Train - Loss: 13.1600 Accuracy: 0.9952\n",
      "Valid - Loss: 19.4343 Accuracy: 0.9852\n",
      "Epoch: 14\n",
      "Train - Loss: 13.5228 Accuracy: 0.9950\n",
      "Valid - Loss: 20.6522 Accuracy: 0.9817\n",
      "Epoch: 15\n",
      "Train - Loss: 14.8456 Accuracy: 0.9950\n",
      "Valid - Loss: 15.6229 Accuracy: 0.9776\n",
      "Epoch: 16\n",
      "Train - Loss: 13.8747 Accuracy: 0.9947\n",
      "Valid - Loss: 29.7398 Accuracy: 0.9534\n",
      "Epoch: 17\n",
      "Train - Loss: 9.0080 Accuracy: 0.9969\n",
      "Valid - Loss: 14.3220 Accuracy: 0.9870\n",
      "Epoch: 18\n",
      "Train - Loss: 13.7623 Accuracy: 0.9950\n",
      "Valid - Loss: 28.2204 Accuracy: 0.9714\n",
      "Epoch: 19\n",
      "Train - Loss: 13.3764 Accuracy: 0.9945\n",
      "Valid - Loss: 14.4839 Accuracy: 0.9805\n"
     ]
    }
   ],
   "source": [
    "epochs = 20\n",
    "\n",
    "for epoch in range(epochs):\n",
    "    print('Epoch: {}'.format(epoch))\n",
    "    train()\n",
    "    validate()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "h0WoN84J3Y-l"
   },
   "source": [
    "## Discussion of Results"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "-EPTunxK3Y-l"
   },
   "source": [
    "You will notice that the validation accuracy is higher, and more consistent. This means that our model is no longer overfitting in the way it was; it generalizes better, making better predictions on new data.\n",
    "\n",
    "The training accuracy may be lower, and that's ok. Compared to before, the model is being exposed to a much larger variety of data."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "npYY9cvA3Y-l"
   },
   "source": [
    "## Saving the Model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "EW_TgWkN3Y-l"
   },
   "source": [
    "Now that we have a well-trained model, we will want to deploy it to perform inference on new images.\n",
    "\n",
    "It is common, once we have a trained model that we are happy with to save it to disk. PyTorch has [multiple ways](https://pytorch.org/tutorials/beginner/saving_loading_models.html) to do this, but for now, we will use `torch.save`. We will also need to save the code for our `MyConvBlock` custom module, which we did in [utils.py](./utils.py). In the next notebook, we'll load the model and use it to read new sign language pictures.\n",
    "\n",
    "PyTorch cannot save a compiled model ([see this post](https://discuss.pytorch.org/t/how-to-save-load-a-model-with-torch-compile/179739)), so we will instead "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "executionInfo": {
     "elapsed": 326,
     "status": "ok",
     "timestamp": 1715241533765,
     "user": {
      "displayName": "Danielle Detering US",
      "userId": "15432464718872067879"
     },
     "user_tz": 420
    },
    "id": "snAS8LalsMv4"
   },
   "outputs": [],
   "source": [
    "torch.save(model, 'model.pth')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "hfePFALr3Y-l"
   },
   "source": [
    "## Summary"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "7fo5z3M03Y-l"
   },
   "source": [
    "In this section, you used TorchVision to augment a dataset. This resulted in a trained model with less overfitting and excellent validation image results."
   ]
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "gpuType": "T4",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "cs5388-a1",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
